time=2025-11-09T23:15:54.520-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:15:54.520-07:00 level=INFO source=images.go:522 msg="total blobs: 0"
time=2025-11-09T23:15:54.520-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:15:54.520-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-09T23:15:54.521-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:15:54.521-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41169"
time=2025-11-09T23:15:54.706-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45581"
time=2025-11-09T23:15:54.906-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39835"
time=2025-11-09T23:15:54.906-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42787"
time=2025-11-09T23:15:55.341-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:15:59 | 200 |      72.857µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:15:59 | 404 |     157.746µs |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:15:59 | 200 |      18.024µs |       127.0.0.1 | HEAD     "/"
time=2025-11-09T23:16:00.064-07:00 level=INFO source=download.go:177 msg="downloading f535f83ec568 in 3 100 MB part(s)"
time=2025-11-09T23:16:04.281-07:00 level=INFO source=download.go:177 msg="downloading fbacade46b4d in 1 68 B part(s)"
time=2025-11-09T23:16:05.512-07:00 level=INFO source=download.go:177 msg="downloading d502d55c1d60 in 1 675 B part(s)"
time=2025-11-09T23:16:06.734-07:00 level=INFO source=download.go:177 msg="downloading 58d1e17ffe51 in 1 11 KB part(s)"
time=2025-11-09T23:16:07.954-07:00 level=INFO source=download.go:177 msg="downloading f02dd72bb242 in 1 59 B part(s)"
time=2025-11-09T23:16:09.212-07:00 level=INFO source=download.go:177 msg="downloading b0f58c4c1a3c in 1 561 B part(s)"
[GIN] 2025/11/09 - 23:16:10 | 200 | 10.899604076s |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/11/09 - 23:24:07 | 200 |     466.706µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:41:10.493-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:41:10.493-07:00 level=INFO source=images.go:522 msg="total blobs: 6"
time=2025-11-09T23:41:10.493-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:41:10.494-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-09T23:41:10.494-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:41:10.494-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41245"
time=2025-11-09T23:41:10.688-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35419"
time=2025-11-09T23:41:11.137-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37887"
time=2025-11-09T23:41:11.137-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45379"
time=2025-11-09T23:41:11.359-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:41:15 | 200 |      45.025µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:41:15 | 404 |     215.405µs |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:41:15 | 200 |      29.325µs |       127.0.0.1 | HEAD     "/"
time=2025-11-09T23:41:16.045-07:00 level=INFO source=download.go:177 msg="downloading 735af2139dc6 in 3 100 MB part(s)"
time=2025-11-09T23:41:20.250-07:00 level=INFO source=download.go:177 msg="downloading 4b19ac7dd2fb in 1 476 B part(s)"
time=2025-11-09T23:41:21.480-07:00 level=INFO source=download.go:177 msg="downloading 3e2c24001f9e in 1 8.4 KB part(s)"
time=2025-11-09T23:41:22.694-07:00 level=INFO source=download.go:177 msg="downloading 339e884a40f6 in 1 61 B part(s)"
time=2025-11-09T23:41:23.911-07:00 level=INFO source=download.go:177 msg="downloading 74156d92caf6 in 1 490 B part(s)"
[GIN] 2025/11/09 - 23:41:25 | 200 |  9.635951598s |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/11/09 - 23:41:50 | 200 |     485.492µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:51:05.006-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:51:05.007-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-09T23:51:05.007-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:51:05.007-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-09T23:51:05.007-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:51:05.008-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39647"
time=2025-11-09T23:51:05.251-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 46703"
time=2025-11-09T23:51:05.435-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38625"
time=2025-11-09T23:51:05.435-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36157"
time=2025-11-09T23:51:05.654-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:51:10 | 200 |       32.06µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:51:10 | 200 |   44.672442ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:51:25 | 200 |     286.358µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:59:12.198-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:59:12.198-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-09T23:59:12.198-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:59:12.199-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-09T23:59:12.199-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:59:12.200-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33841"
time=2025-11-09T23:59:12.403-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45673"
time=2025-11-09T23:59:12.850-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41649"
time=2025-11-09T23:59:12.850-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35973"
time=2025-11-09T23:59:13.067-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:59:17 | 200 |      30.107µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:59:17 | 200 |   44.156367ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:59:32 | 200 |     502.514µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:06:31.388-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:06:31.388-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:06:31.388-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:06:31.388-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-10T00:06:31.389-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:06:31.390-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39559"
time=2025-11-10T00:06:31.598-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39717"
time=2025-11-10T00:06:32.068-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45859"
time=2025-11-10T00:06:32.068-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45105"
time=2025-11-10T00:06:32.280-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:06:36 | 200 |       53.53µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:06:36 | 200 |   46.484513ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:06:52 | 200 |     343.044µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:12:46.238-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:12:46.238-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:12:46.238-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:12:46.239-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-10T00:12:46.239-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:12:46.240-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33727"
time=2025-11-10T00:12:46.456-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 40317"
time=2025-11-10T00:12:46.664-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45071"
time=2025-11-10T00:12:46.664-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33673"
time=2025-11-10T00:12:47.164-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:12:51 | 200 |      38.702µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:12:51 | 200 |   48.237103ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:13:07 | 200 |     508.945µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:19:24.391-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:19:24.392-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:19:24.392-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:19:24.392-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-10T00:19:24.392-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:19:24.393-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44307"
time=2025-11-10T00:19:24.606-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33905"
time=2025-11-10T00:19:24.991-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33321"
time=2025-11-10T00:19:24.991-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39077"
time=2025-11-10T00:19:25.294-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:19:29 | 200 |      30.257µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:19:29 | 200 |   56.079821ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:19:45 | 200 |     497.845µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:27:47.693-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:27:47.693-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:27:47.694-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:27:47.694-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-10T00:27:47.694-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:27:47.694-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 40119"
time=2025-11-10T00:27:48.124-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 40801"
time=2025-11-10T00:27:48.342-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41867"
time=2025-11-10T00:27:48.342-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38043"
time=2025-11-10T00:27:48.574-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:27:52 | 200 |      39.445µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:27:52 | 200 |   54.588573ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:28:08 | 200 |     388.901µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:38:45.633-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:38:45.649-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:38:45.649-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:38:45.649-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-10T00:38:45.650-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:38:45.650-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33903"
time=2025-11-10T00:38:45.867-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42571"
time=2025-11-10T00:38:46.076-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33535"
time=2025-11-10T00:38:46.076-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 40445"
time=2025-11-10T00:38:46.321-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:38:50 | 200 |      58.941µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:38:50 | 200 |   50.220147ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:39:06 | 200 |      511.04µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:49:19.945-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:49:19.945-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:49:19.945-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:49:19.946-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-10T00:49:19.946-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:49:19.946-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42765"
time=2025-11-10T00:49:20.415-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35301"
time=2025-11-10T00:49:20.632-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33957"
time=2025-11-10T00:49:20.632-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39183"
time=2025-11-10T00:49:20.866-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:49:24 | 200 |      40.847µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:49:24 | 200 |   47.078615ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:49:40 | 200 |     472.938µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:09:19.500-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:09:19.501-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:09:19.501-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:09:19.501-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-10T01:09:19.501-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:09:19.502-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44977"
time=2025-11-10T01:09:19.707-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39607"
time=2025-11-10T01:09:20.157-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45743"
time=2025-11-10T01:09:20.157-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42659"
time=2025-11-10T01:09:20.360-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:09:24 | 200 |      44.153µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:09:24 | 200 |   45.545523ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:09:40 | 200 |     709.192µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:16:30.361-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:16:30.361-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:16:30.361-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:16:30.361-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-10T01:16:30.361-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:16:30.362-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43085"
time=2025-11-10T01:16:30.559-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37527"
time=2025-11-10T01:16:30.994-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45815"
time=2025-11-10T01:16:30.994-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 34711"
time=2025-11-10T01:16:31.194-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:16:35 | 200 |      35.587µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:16:35 | 200 |   45.359025ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:16:51 | 200 |     407.856µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:40:14.463-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:40:14.463-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:40:14.463-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:40:14.463-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-10T01:40:14.464-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:40:14.465-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43343"
time=2025-11-10T01:40:14.670-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33065"
time=2025-11-10T01:40:14.870-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42585"
time=2025-11-10T01:40:14.870-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 46373"
time=2025-11-10T01:40:15.353-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:40:16 | 200 |      39.103µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:40:16 | 200 |   47.557244ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:40:24 | 200 |     278.814µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:41:06.601-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36991"
time=2025-11-10T01:41:07.313-07:00 level=INFO source=server.go:215 msg="enabling flash attention"
time=2025-11-10T01:41:07.313-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /home/dan/.ollama-11480/blobs/sha256-735af2139dc652bf01112746474883d79a52fa1c19038265d363e3d42556f7a2 --port 46181"
time=2025-11-10T01:41:07.315-07:00 level=INFO source=server.go:653 msg="loading model" "model layers"=19 requested=-1
time=2025-11-10T01:41:07.315-07:00 level=INFO source=server.go:658 msg="system memory" total="123.6 GiB" free="91.7 GiB" free_swap="0 B"
time=2025-11-10T01:41:07.315-07:00 level=INFO source=server.go:665 msg="gpu memory" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f library=CUDA available="15.1 GiB" free="15.6 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-10T01:41:07.336-07:00 level=INFO source=runner.go:1349 msg="starting ollama engine"
time=2025-11-10T01:41:07.336-07:00 level=INFO source=runner.go:1384 msg="Server listening on 127.0.0.1:46181"
time=2025-11-10T01:41:07.337-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:41:07.417-07:00 level=INFO source=ggml.go:136 msg="" architecture=gemma3 file_type=Q8_0 name="" description="" num_tensors=236 num_key_values=37
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-10T01:41:08.171-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-10T01:41:08.867-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:41:09.045-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:41:09.046-07:00 level=INFO source=device.go:212 msg="model weights" device=CUDA0 size="271.9 MiB"
time=2025-11-10T01:41:09.050-07:00 level=INFO source=device.go:217 msg="model weights" device=CPU size="170.0 MiB"
time=2025-11-10T01:41:09.050-07:00 level=INFO source=device.go:223 msg="kv cache" device=CUDA0 size="27.0 MiB"
time=2025-11-10T01:41:09.050-07:00 level=INFO source=device.go:234 msg="compute graph" device=CUDA0 size="155.5 MiB"
time=2025-11-10T01:41:09.050-07:00 level=INFO source=device.go:239 msg="compute graph" device=CPU size="1.2 MiB"
time=2025-11-10T01:41:09.050-07:00 level=INFO source=device.go:244 msg="total memory" size="625.6 MiB"
time=2025-11-10T01:41:09.050-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-10T01:41:09.051-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-10T01:41:09.046-07:00 level=INFO source=ggml.go:482 msg="offloading 18 repeating layers to GPU"
time=2025-11-10T01:41:09.046-07:00 level=INFO source=ggml.go:489 msg="offloading output layer to GPU"
time=2025-11-10T01:41:09.047-07:00 level=INFO source=ggml.go:494 msg="offloaded 19/19 layers to GPU"
time=2025-11-10T01:41:09.053-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
time=2025-11-10T01:41:09.806-07:00 level=INFO source=server.go:1289 msg="llama runner started in 2.49 seconds"
[GIN] 2025/11/10 - 01:41:10 | 200 |  4.344408493s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:11 | 200 |  1.008759641s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:12 | 200 |  753.103152ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:12 | 200 |  1.017899455s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:13 | 200 |  912.291162ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:24 | 200 |  844.485928ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:26 | 200 |  2.286794871s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:29 | 200 |  2.531226511s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:30 | 200 |  3.129640769s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:32 | 200 |  1.861933827s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:34 | 200 |  3.750494321s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:36 | 200 |  3.939504522s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:38 | 200 |  3.573181157s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:41:38.957-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7797 keep=4 new=4096
[GIN] 2025/11/10 - 01:41:39 | 200 |  3.520190423s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:40 | 200 |  3.041060344s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:41:41.391-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7892 keep=4 new=4096
[GIN] 2025/11/10 - 01:41:42 | 200 |  2.532131372s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:43 | 200 |  2.772173564s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:41:43.875-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7892 keep=4 new=4096
[GIN] 2025/11/10 - 01:41:44 | 200 |  2.162474885s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:45 | 200 |  1.687983956s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:56 | 200 |  1.070912027s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:16 | 200 |  5.296279888s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:21 | 200 |  5.491001665s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:26 | 200 | 11.899784218s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:31 | 200 | 14.314471004s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:35 | 200 |  17.85701274s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:39 | 200 | 20.229624153s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:43 | 200 | 18.224130233s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:47 | 200 | 14.391048942s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:54 | 200 | 16.351979455s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:59 | 200 | 14.299006773s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:04 | 200 | 16.846719463s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:10 | 200 | 19.641721351s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:14 | 200 | 18.402354802s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:18 | 200 | 16.023283419s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:22 | 200 | 12.856986287s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:25 | 200 |  10.96185852s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:28 | 200 |  8.009459059s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:31 | 200 |  8.526512331s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:33 | 200 |  7.378777341s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:38 | 200 |  5.709401425s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:44 | 200 | 10.528114105s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:50 | 200 |   11.5282785s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:53 | 200 | 13.645057569s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:58 | 200 | 12.987269093s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:03 | 200 | 10.814099678s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:08 | 200 | 14.536303353s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:12 | 200 | 13.423683875s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:15 | 200 | 10.626953478s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:20 | 200 |  9.054558552s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:24 | 200 | 11.392365408s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:27 | 200 | 11.624243943s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:30 | 200 | 11.531927725s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:31 | 200 |  6.572545387s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:37 | 200 |  6.944550471s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:44 | 200 | 12.960525544s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:50 | 200 | 12.822378778s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:53 | 200 |  9.200581531s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:56 | 200 |  6.093210061s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:01 | 200 |  8.090348338s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:05 | 200 |  8.492785721s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:11 | 200 | 14.586739981s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:14 | 200 |  12.37994226s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:17 | 200 |  9.030169084s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:21 | 200 |  7.275641296s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:27 | 200 |  8.569996736s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:31 | 200 | 10.414407856s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:37 | 200 | 14.879383854s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:39 | 200 | 12.945940198s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:43 | 200 | 11.657533948s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:48 | 200 | 15.045092889s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:54 | 200 | 16.336494221s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:59 | 200 | 18.649376087s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:03 | 200 | 19.501679277s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:09 | 200 | 23.684827986s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:11 | 200 | 20.119553903s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:15 | 200 | 17.821039119s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:19 | 200 | 19.873787097s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:23 | 200 | 20.136200488s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:28 | 200 | 17.955671064s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:34 | 200 | 18.174840668s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:38 | 200 |  21.78620434s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:44 | 200 | 22.037776653s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:49 | 200 | 19.437770794s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:54 | 200 |  17.93897492s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:58 | 200 | 15.814082335s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:03 | 200 |  4.345058949s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:29 | 200 |  7.326696387s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:34 | 200 |  9.553751484s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:38 | 200 | 12.676757605s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:42 | 200 | 17.046074274s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:46 | 200 | 21.073836507s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:53 | 200 | 21.986978267s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:57 | 200 | 18.805237983s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:02 | 200 |  18.32637094s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:07 | 200 | 20.688055411s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:13 | 200 | 23.192514253s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:19 | 200 | 21.602411739s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:25 | 200 |  27.64473989s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:29 | 200 | 26.437034705s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:31 | 200 | 21.400718758s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:35 | 200 | 19.851013425s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:40 | 200 | 19.211585043s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:44 | 200 | 17.169340491s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:49 | 200 | 18.201514247s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:55 | 200 | 22.252770774s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:00 | 200 | 21.536841703s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:03 | 200 | 19.607787114s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:07 | 200 |  16.85203146s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:14 | 200 | 16.610553173s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:19 | 200 | 14.825218895s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:24 | 200 | 13.396008761s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:29 | 200 | 11.480694656s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:34 | 200 |  10.09706429s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:38 | 200 |  8.018362603s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:42 | 200 |  6.701468572s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:46 | 200 |  3.983112338s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:51 | 200 |  4.758159408s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:53 | 200 |  4.423003378s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:59 | 200 |  6.044642788s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:04 | 200 |  9.109108165s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:05 | 200 |  3.630553304s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:11 | 200 |  5.359460518s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:18 | 200 | 10.113047211s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:25 | 200 |  9.693617414s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:28 | 200 |  6.282425807s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:38 | 200 |   10.0667117s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:42 | 200 |  9.368121881s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:48 | 200 |  7.803385059s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:52 | 200 |  6.339166957s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:55 | 200 |   4.59017711s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:02 | 200 |  6.022604184s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:05 | 200 |  2.136586365s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:14 | 200 |  4.176361284s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:20 | 200 |  5.227912605s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:24 | 200 |  8.681214496s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:28 | 200 |   6.67673943s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:33 | 200 |  8.790390118s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:36 | 200 |  8.030128073s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:43 | 200 |  8.309288568s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:46 | 200 |  9.013677957s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:49 | 200 |   8.20916668s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:54 | 200 |  6.534139891s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:59 | 200 |  8.967944081s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:03 | 200 |  9.250169445s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:06 | 200 |  4.646249513s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:13 | 200 |  9.388322038s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:19 | 200 | 13.119381116s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:21 | 200 | 12.916186349s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:26 | 200 | 11.907925126s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:31 | 200 |  9.440672452s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:34 | 200 | 11.945499214s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:38 | 200 |  7.758851969s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:44 | 200 |  7.083188655s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:49 | 200 | 11.219366255s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:53 | 200 | 10.370959644s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:58 | 200 | 14.408640452s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:02 | 200 |  12.80457406s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:09 | 200 |  16.16294404s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:15 | 200 | 18.484072926s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:20 | 200 | 17.322778553s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:25 | 200 | 20.087621841s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:27 | 200 | 15.114947248s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:30 | 200 | 11.942785041s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:35 | 200 | 10.584673662s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:39 | 200 | 12.677394559s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:44 | 200 | 12.271662439s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:49 | 200 | 10.393983283s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:55 | 200 |  7.935907775s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:57 | 200 |  4.882337359s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:03 | 200 |    7.7182124s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:08 | 200 |  8.586862595s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:13 | 200 |  6.170701611s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:21 | 200 |  8.534976817s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:27 | 200 | 13.948064224s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:34 | 200 | 11.951690627s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:38 | 200 | 11.170412328s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:40 | 200 | 11.351667121s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:43 | 200 |  7.692558074s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:49 | 200 |  6.663035938s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:54 | 200 |  4.819884064s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:01 | 200 |  6.772216481s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:05 | 200 |  8.895888305s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:07 | 200 |  5.475152661s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:10 | 200 |  3.985333162s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:14 | 200 |  7.146742895s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:20 | 200 | 10.263160405s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:25 | 200 |  8.469768654s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:29 | 200 |  5.400922965s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:36 | 200 |  6.242705075s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:43 | 200 |  6.392625364s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:50 | 200 |  7.488780268s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:54 | 200 | 10.986376227s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:59 | 200 |  9.940174312s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:03 | 200 |  7.929088338s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:09 | 200 |  7.638826131s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:14 | 200 | 11.010917097s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:20 | 200 | 11.818701379s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:24 | 200 | 10.769916484s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:27 | 200 |  7.442147194s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:32 | 200 |  11.94027572s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:37 | 200 | 12.508192838s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:44 | 200 | 17.556019893s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:48 | 200 | 15.760498318s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:51 | 200 | 17.836549246s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:54 | 200 | 16.696401616s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:57 | 200 | 11.727727131s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:00 | 200 |  9.403141232s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:04 | 200 |  6.376758705s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:11 | 200 | 10.009100727s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:15 | 200 | 11.822704697s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:19 | 200 |  8.463461673s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:24 | 200 |  7.014383848s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:31 | 200 | 11.394097734s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:36 | 200 | 13.417157475s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:40 | 200 | 10.538142102s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:46 | 200 |  9.696602297s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:51 | 200 | 10.648565397s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:54 | 200 | 12.064279809s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:58 | 200 |  9.659402285s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:02 | 200 |  7.039852512s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:05 | 200 |  6.901452791s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:10 | 200 |  7.919667511s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:16 | 200 | 13.192958701s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:19 | 200 |  11.54541091s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:22 | 200 |  8.726289888s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:26 | 200 |  5.969304664s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:32 | 200 |  5.277987485s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:39 | 200 | 12.411579175s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:42 | 200 |  8.382806797s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:45 | 200 |  5.922391386s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:50 | 200 |  7.212595208s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:56 | 200 | 10.808903347s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:58 | 200 |  5.636448538s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:03 | 200 |  6.414961827s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:05 | 200 |  7.338629505s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:09 | 200 |  9.522615198s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:12 | 200 |  6.661238441s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:18 | 200 |  6.378562685s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:26 | 200 |  7.364855143s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:31 | 200 |   6.08570177s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:36 | 200 |    4.8713321s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:42 | 200 |  6.090939265s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:48 | 200 | 10.521551904s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:53 | 200 |  8.862929651s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:56 | 200 |  5.561416445s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:06 | 200 |  9.072809911s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:11 | 200 |  7.308979523s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:17 | 200 | 10.659630885s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:23 | 200 | 12.943747091s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:31 | 200 | 15.757163948s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:37 | 200 | 15.671772293s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:42 | 200 |  19.07008417s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:47 | 200 | 19.812974103s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:51 | 200 | 17.843686548s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:54 | 200 | 14.574002382s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:58 | 200 | 11.613824826s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:02 | 200 |  11.20072469s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:06 | 200 | 14.162166472s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:09 | 200 | 14.644446062s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:13 | 200 |  14.03067548s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:16 | 200 | 10.701114859s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:24 | 200 | 17.204456881s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:26 | 200 | 14.337816532s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:28 | 200 | 10.901537279s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:32 | 200 |  7.712356738s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:37 | 200 |   8.14964988s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:42 | 200 | 11.319868199s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:47 | 200 |  9.642774877s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:27 | 200 |  6.936295738s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:31 | 200 | 12.018346633s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:35 | 200 | 15.376241676s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:39 | 200 | 18.923316183s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:42 | 200 | 22.052484382s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:46 | 200 | 19.126215819s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:51 | 200 | 19.458677306s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:56 | 200 |  20.84993642s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:02 | 200 | 22.790820757s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:07 | 200 | 24.844756614s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:11 | 200 | 23.318974039s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:15 | 200 | 23.336181351s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:19 | 200 | 22.454633183s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:25 | 200 | 22.699156508s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:30 | 200 | 22.915668156s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:36 | 200 | 24.808801087s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:40 | 200 | 24.985861098s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:45 | 200 |  25.31613238s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:50 | 200 | 24.557729266s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:54 | 200 | 22.114797098s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:59 | 200 | 23.266316052s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:05 | 200 | 24.091697146s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:10 | 200 | 24.312633027s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:14 | 200 | 23.695668218s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:19 | 200 | 25.366607738s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:23 | 200 | 23.456482074s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:28 | 200 | 23.291131402s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:33 | 200 | 22.784153579s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:36 | 200 | 20.307534508s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:39 | 200 | 17.215654067s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:44 | 200 | 15.348970223s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:48 | 200 | 13.507180349s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:52 | 200 | 12.418240063s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:57 | 200 |  16.66649763s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:02 | 200 | 14.930902734s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:05 | 200 | 12.858166116s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:08 | 200 | 10.723817408s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:11 | 200 | 12.713077067s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:18 | 200 | 15.456404508s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:21 | 200 | 16.010753722s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:26 | 200 | 20.561385709s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:32 | 200 |  21.52241886s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:38 | 200 | 24.756197532s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:41 | 200 | 22.617285577s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:45 | 200 | 21.299343225s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:50 | 200 | 23.659702769s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:55 | 200 | 22.645966568s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:59 | 200 | 21.146318677s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:10 | 200 | 26.697280716s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:14 | 200 | 24.762117913s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:20 | 200 | 23.510995423s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:26 | 200 | 26.462939797s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:31 | 200 | 29.017682999s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:37 | 200 | 26.823532308s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:43 | 200 | 27.754284822s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:50 | 200 | 29.213199292s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:54 | 200 | 26.289734548s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:58 | 200 | 26.230516398s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:06:59.989-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:06:59 | 500 |  4.850142133s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:07:00.008-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:07:00 | 500 | 16.304630089s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:07:00.009-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:07:00 | 500 |  9.122812896s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:07:00 | 200 | 23.118848741s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:08:39.477-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11480 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11480 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T02:08:39.478-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T02:08:39.478-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T02:08:39.478-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11480 (version 0.12.9)"
time=2025-11-10T02:08:39.478-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T02:08:39.479-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36871"
time=2025-11-10T02:08:39.679-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41553"
time=2025-11-10T02:08:39.882-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45057"
time=2025-11-10T02:08:39.882-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38239"
time=2025-11-10T02:08:40.101-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 02:08:41 | 200 |       48.36µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 02:08:41 | 200 |   44.190901ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 02:08:49 | 200 |     519.656µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T02:09:32.313-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 34863"
time=2025-11-10T02:09:33.015-07:00 level=INFO source=server.go:215 msg="enabling flash attention"
time=2025-11-10T02:09:33.019-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /home/dan/.ollama-11480/blobs/sha256-735af2139dc652bf01112746474883d79a52fa1c19038265d363e3d42556f7a2 --port 33389"
time=2025-11-10T02:09:33.021-07:00 level=INFO source=server.go:653 msg="loading model" "model layers"=19 requested=-1
time=2025-11-10T02:09:33.021-07:00 level=INFO source=server.go:658 msg="system memory" total="123.6 GiB" free="92.3 GiB" free_swap="0 B"
time=2025-11-10T02:09:33.022-07:00 level=INFO source=server.go:665 msg="gpu memory" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f library=CUDA available="16.0 GiB" free="16.4 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-10T02:09:33.056-07:00 level=INFO source=runner.go:1349 msg="starting ollama engine"
time=2025-11-10T02:09:33.056-07:00 level=INFO source=runner.go:1384 msg="Server listening on 127.0.0.1:33389"
time=2025-11-10T02:09:33.066-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:33.127-07:00 level=INFO source=ggml.go:136 msg="" architecture=gemma3 file_type=Q8_0 name="" description="" num_tensors=236 num_key_values=37
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-10T02:09:33.599-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-10T02:09:34.081-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:34.211-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:34.211-07:00 level=INFO source=ggml.go:482 msg="offloading 18 repeating layers to GPU"
time=2025-11-10T02:09:34.211-07:00 level=INFO source=ggml.go:489 msg="offloading output layer to GPU"
time=2025-11-10T02:09:34.211-07:00 level=INFO source=ggml.go:494 msg="offloaded 19/19 layers to GPU"
time=2025-11-10T02:09:34.212-07:00 level=INFO source=device.go:212 msg="model weights" device=CUDA0 size="271.9 MiB"
time=2025-11-10T02:09:34.212-07:00 level=INFO source=device.go:217 msg="model weights" device=CPU size="170.0 MiB"
time=2025-11-10T02:09:34.212-07:00 level=INFO source=device.go:223 msg="kv cache" device=CUDA0 size="27.0 MiB"
time=2025-11-10T02:09:34.212-07:00 level=INFO source=device.go:234 msg="compute graph" device=CUDA0 size="155.5 MiB"
time=2025-11-10T02:09:34.212-07:00 level=INFO source=device.go:239 msg="compute graph" device=CPU size="1.2 MiB"
time=2025-11-10T02:09:34.212-07:00 level=INFO source=device.go:244 msg="total memory" size="625.6 MiB"
time=2025-11-10T02:09:34.213-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-10T02:09:34.214-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-10T02:09:34.225-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
time=2025-11-10T02:09:34.733-07:00 level=INFO source=server.go:1289 msg="llama runner started in 1.71 seconds"
[GIN] 2025/11/10 - 02:09:35 | 200 |    3.8135035s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:36 | 200 |    976.1335ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:37 | 200 |  1.282055358s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:37 | 200 |  1.127779137s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:38 | 200 |  1.123312515s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:48 | 200 |  584.814828ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:50 | 200 |  1.255565358s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:52 | 200 |  1.833221479s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:53 | 200 |  1.777580862s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:55 | 200 |  1.661353382s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:56 | 200 |  1.462230769s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:57 | 200 |  1.513352301s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:59 | 200 |   1.42489286s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:10:00.354-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7797 keep=4 new=4096
[GIN] 2025/11/10 - 02:10:01 | 200 |  1.383390504s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:02 | 200 |   1.35914732s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:10:02.454-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7892 keep=4 new=4096
[GIN] 2025/11/10 - 02:10:03 | 200 |  1.843009744s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:03 | 200 |   1.84484869s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:10:04.291-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7892 keep=4 new=4096
[GIN] 2025/11/10 - 02:10:04 | 200 |  1.634388027s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:05 | 200 |  1.652842762s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:21 | 200 |  2.724155054s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:24 | 200 |  2.599374852s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:26 | 200 |  2.230835999s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:13 | 200 |  2.088724564s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:24 | 200 | 10.068430106s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:33 | 200 | 17.816622234s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:37 | 200 | 18.020002086s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:41 | 200 | 21.126145672s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:45 | 200 | 25.245115242s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:49 | 200 | 26.595565806s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:52 | 200 | 30.195569273s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:56 | 200 | 29.977382916s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:00 | 200 | 33.302344045s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:04 | 200 | 37.679401294s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:11 | 200 | 41.619429912s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:16.345-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:16 | 500 | 45.026096705s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:16 | 200 | 46.860593123s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:18 | 500 | 45.046991388s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:19.858-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:22 | 200 | 44.072610656s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:25 | 200 | 43.239278899s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:29 | 200 |  42.81393821s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:33 | 200 | 44.214984569s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:38 | 200 | 45.845298721s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:42 | 200 | 45.407815906s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:46 | 200 | 45.780901793s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:50 | 500 | 45.067052803s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:51 | 500 | 45.103654683s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:52 | 500 | 45.051815802s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:52.453-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
time=2025-11-10T02:13:54.529-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
time=2025-11-10T02:13:56.550-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:56 | 500 | 45.048347257s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:59 | 200 | 47.523122569s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:00 | 500 | 45.068110174s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:02 | 500 | 45.066452413s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:03.410-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:03 | 500 | 45.046807886s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:03.973-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:05 | 200 |  43.12043367s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:10 | 200 | 44.204901757s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:15 | 200 | 45.296395011s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:19 | 200 | 44.946998803s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.442-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 | 12.214468099s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.459-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 | 21.752828591s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.459-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 |  4.165670692s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.460-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 | 38.584113113s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.460-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 | 15.674301897s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:22 | 200 | 44.410569583s |       127.0.0.1 | POST     "/api/generate"
