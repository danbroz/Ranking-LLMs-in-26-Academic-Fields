time=2025-11-09T23:10:54.111-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:10:54.112-07:00 level=INFO source=images.go:522 msg="total blobs: 0"
time=2025-11-09T23:10:54.112-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:10:54.112-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-09T23:10:54.112-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:10:54.112-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39951"
time=2025-11-09T23:10:54.534-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43891"
time=2025-11-09T23:10:54.712-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39381"
time=2025-11-09T23:10:54.712-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39395"
time=2025-11-09T23:10:54.941-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:10:59 | 200 |      48.602µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:10:59 | 404 |     148.469µs |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:10:59 | 200 |      24.837µs |       127.0.0.1 | HEAD     "/"
time=2025-11-09T23:10:59.629-07:00 level=INFO source=download.go:177 msg="downloading f535f83ec568 in 3 100 MB part(s)"
time=2025-11-09T23:11:02.876-07:00 level=INFO source=download.go:177 msg="downloading fbacade46b4d in 1 68 B part(s)"
time=2025-11-09T23:11:04.110-07:00 level=INFO source=download.go:177 msg="downloading d502d55c1d60 in 1 675 B part(s)"
time=2025-11-09T23:11:05.343-07:00 level=INFO source=download.go:177 msg="downloading 58d1e17ffe51 in 1 11 KB part(s)"
time=2025-11-09T23:11:06.556-07:00 level=INFO source=download.go:177 msg="downloading f02dd72bb242 in 1 59 B part(s)"
time=2025-11-09T23:11:07.797-07:00 level=INFO source=download.go:177 msg="downloading b0f58c4c1a3c in 1 561 B part(s)"
[GIN] 2025/11/09 - 23:11:09 | 200 |  9.890847473s |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/11/09 - 23:24:06 | 200 |     331.732µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:24:08.451-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33159"
llama_model_loader: loaded meta data with 33 key-value pairs and 272 tensors from /home/dan/.ollama-11460/blobs/sha256-f535f83ec568d040f88ddc04a199fa6da90923bbb41d4dcaed02caa924d6ef57 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Smollm2 135M 8k Lc100K Mix1 Ep2
llama_model_loader: - kv   3:                       general.organization str              = HuggingFaceTB
llama_model_loader: - kv   4:                           general.finetune str              = 8k-lc100k-mix1-ep2
llama_model_loader: - kv   5:                           general.basename str              = smollm2
llama_model_loader: - kv   6:                         general.size_label str              = 135M
llama_model_loader: - kv   7:                            general.license str              = apache-2.0
llama_model_loader: - kv   8:                          general.languages arr[str,1]       = ["en"]
llama_model_loader: - kv   9:                          llama.block_count u32              = 30
llama_model_loader: - kv  10:                       llama.context_length u32              = 8192
llama_model_loader: - kv  11:                     llama.embedding_length u32              = 576
llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 1536
llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 9
llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 3
llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 100000.000000
llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  17:                          general.file_type u32              = 1
llama_model_loader: - kv  18:                           llama.vocab_size u32              = 49152
llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 64
llama_model_loader: - kv  20:            tokenizer.ggml.add_space_prefix bool             = false
llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = smollm
llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,49152]   = ["<|endoftext|>", "<|im_start|>", "<|...
llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,49152]   = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...
llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,48900]   = ["Ġ t", "Ġ a", "i n", "h e", "Ġ Ġ...
llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 1
llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 2
llama_model_loader: - kv  29:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  30:            tokenizer.ggml.padding_token_id u32              = 2
llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {% for message in messages %}{% if lo...
llama_model_loader: - kv  32:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type  f16:  211 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = F16
print_info: file size   = 256.63 MiB (16.00 BPW) 
load: printing all EOG tokens:
load:   - 0 ('<|endoftext|>')
load:   - 2 ('<|im_end|>')
load:   - 4 ('<reponame>')
load: special tokens cache size = 17
load: token to piece cache size = 0.3170 MB
print_info: arch             = llama
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 134.52 M
print_info: general.name     = Smollm2 135M 8k Lc100K Mix1 Ep2
print_info: vocab type       = BPE
print_info: n_vocab          = 49152
print_info: n_merges         = 48900
print_info: BOS token        = 1 '<|im_start|>'
print_info: EOS token        = 2 '<|im_end|>'
print_info: EOT token        = 0 '<|endoftext|>'
print_info: UNK token        = 0 '<|endoftext|>'
print_info: PAD token        = 2 '<|im_end|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM REP token    = 4 '<reponame>'
print_info: EOG token        = 0 '<|endoftext|>'
print_info: EOG token        = 2 '<|im_end|>'
print_info: EOG token        = 4 '<reponame>'
print_info: max token length = 162
llama_model_load: vocab only - skipping tensors
time=2025-11-09T23:24:08.998-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --model /home/dan/.ollama-11460/blobs/sha256-f535f83ec568d040f88ddc04a199fa6da90923bbb41d4dcaed02caa924d6ef57 --port 36061"
time=2025-11-09T23:24:08.999-07:00 level=INFO source=server.go:470 msg="system memory" total="123.6 GiB" free="109.6 GiB" free_swap="0 B"
time=2025-11-09T23:24:08.999-07:00 level=INFO source=memory.go:37 msg="new model will fit in available VRAM across minimum required GPUs, loading" model=/home/dan/.ollama-11460/blobs/sha256-f535f83ec568d040f88ddc04a199fa6da90923bbb41d4dcaed02caa924d6ef57 library=CUDA parallel=1 required="910.5 MiB" gpus=1
time=2025-11-09T23:24:08.999-07:00 level=INFO source=server.go:522 msg=offload library=CUDA layers.requested=-1 layers.model=31 layers.offload=31 layers.split=[31] memory.available="[23.5 GiB]" memory.gpu_overhead="0 B" memory.required.full="910.5 MiB" memory.required.partial="910.5 MiB" memory.required.kv="90.0 MiB" memory.required.allocations="[910.5 MiB]" memory.weights.total="256.6 MiB" memory.weights.repeating="202.6 MiB" memory.weights.nonrepeating="54.0 MiB" memory.graph.full="97.1 MiB" memory.graph.partial="120.4 MiB"
time=2025-11-09T23:24:09.008-07:00 level=INFO source=runner.go:910 msg="starting go runner"
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-874c91aa-3bb2-54a0-534f-860241e77353
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-09T23:24:09.231-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-09T23:24:09.231-07:00 level=INFO source=runner.go:946 msg="Server listening on 127.0.0.1:36061"
time=2025-11-09T23:24:09.242-07:00 level=INFO source=runner.go:845 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:false KvSize:4096 KvCacheType: NumThreads:8 GPULayers:31[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:31(0..30)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:true}"
time=2025-11-09T23:24:09.242-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-09T23:24:09.243-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
ggml_backend_cuda_device_get_memory device GPU-874c91aa-3bb2-54a0-534f-860241e77353 utilizing NVML memory reporting free: 25229852672 total: 25757220864
llama_model_load_from_file_impl: using device CUDA0 (NVIDIA GeForce RTX 4090) (0000:09:00.0) - 24061 MiB free
llama_model_loader: loaded meta data with 33 key-value pairs and 272 tensors from /home/dan/.ollama-11460/blobs/sha256-f535f83ec568d040f88ddc04a199fa6da90923bbb41d4dcaed02caa924d6ef57 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Smollm2 135M 8k Lc100K Mix1 Ep2
llama_model_loader: - kv   3:                       general.organization str              = HuggingFaceTB
llama_model_loader: - kv   4:                           general.finetune str              = 8k-lc100k-mix1-ep2
llama_model_loader: - kv   5:                           general.basename str              = smollm2
llama_model_loader: - kv   6:                         general.size_label str              = 135M
llama_model_loader: - kv   7:                            general.license str              = apache-2.0
llama_model_loader: - kv   8:                          general.languages arr[str,1]       = ["en"]
llama_model_loader: - kv   9:                          llama.block_count u32              = 30
llama_model_loader: - kv  10:                       llama.context_length u32              = 8192
llama_model_loader: - kv  11:                     llama.embedding_length u32              = 576
llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 1536
llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 9
llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 3
llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 100000.000000
llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  17:                          general.file_type u32              = 1
llama_model_loader: - kv  18:                           llama.vocab_size u32              = 49152
llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 64
llama_model_loader: - kv  20:            tokenizer.ggml.add_space_prefix bool             = false
llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = smollm
llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,49152]   = ["<|endoftext|>", "<|im_start|>", "<|...
llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,49152]   = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...
llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,48900]   = ["Ġ t", "Ġ a", "i n", "h e", "Ġ Ġ...
llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 1
llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 2
llama_model_loader: - kv  29:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  30:            tokenizer.ggml.padding_token_id u32              = 2
llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {% for message in messages %}{% if lo...
llama_model_loader: - kv  32:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type  f16:  211 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = F16
print_info: file size   = 256.63 MiB (16.00 BPW) 
load: printing all EOG tokens:
load:   - 0 ('<|endoftext|>')
load:   - 2 ('<|im_end|>')
load:   - 4 ('<reponame>')
load: special tokens cache size = 17
load: token to piece cache size = 0.3170 MB
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: n_ctx_train      = 8192
print_info: n_embd           = 576
print_info: n_layer          = 30
print_info: n_head           = 9
print_info: n_head_kv        = 3
print_info: n_rot            = 64
print_info: n_swa            = 0
print_info: is_swa_any       = 0
print_info: n_embd_head_k    = 64
print_info: n_embd_head_v    = 64
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 192
print_info: n_embd_v_gqa     = 192
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 1536
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: freq_base_train  = 100000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 8192
print_info: rope_finetuned   = unknown
print_info: model type       = 256M
print_info: model params     = 134.52 M
print_info: general.name     = Smollm2 135M 8k Lc100K Mix1 Ep2
print_info: vocab type       = BPE
print_info: n_vocab          = 49152
print_info: n_merges         = 48900
print_info: BOS token        = 1 '<|im_start|>'
print_info: EOS token        = 2 '<|im_end|>'
print_info: EOT token        = 0 '<|endoftext|>'
print_info: UNK token        = 0 '<|endoftext|>'
print_info: PAD token        = 2 '<|im_end|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM REP token    = 4 '<reponame>'
print_info: EOG token        = 0 '<|endoftext|>'
print_info: EOG token        = 2 '<|im_end|>'
print_info: EOG token        = 4 '<reponame>'
print_info: max token length = 162
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: offloading 30 repeating layers to GPU
load_tensors: offloading output layer to GPU
load_tensors: offloaded 31/31 layers to GPU
load_tensors:        CUDA0 model buffer size =   256.63 MiB
load_tensors:   CPU_Mapped model buffer size =    54.00 MiB
llama_init_from_model: model default pooling_type is [0], but [-1] was specified
llama_context: constructing llama_context
llama_context: n_seq_max     = 1
llama_context: n_ctx         = 4096
llama_context: n_ctx_per_seq = 4096
llama_context: n_batch       = 512
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = disabled
llama_context: kv_unified    = false
llama_context: freq_base     = 100000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (4096) < n_ctx_train (8192) -- the full capacity of the model will not be utilized
llama_context:  CUDA_Host  output buffer size =     0.19 MiB
llama_kv_cache:      CUDA0 KV buffer size =    90.00 MiB
llama_kv_cache: size =   90.00 MiB (  4096 cells,  30 layers,  1/1 seqs), K (f16):   45.00 MiB, V (f16):   45.00 MiB
llama_context:      CUDA0 compute buffer size =    97.12 MiB
llama_context:  CUDA_Host compute buffer size =     9.88 MiB
llama_context: graph nodes  = 1086
llama_context: graph splits = 2
time=2025-11-09T23:24:10.747-07:00 level=INFO source=server.go:1289 msg="llama runner started in 1.75 seconds"
time=2025-11-09T23:24:10.747-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-09T23:24:10.747-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-09T23:24:10.747-07:00 level=INFO source=server.go:1289 msg="llama runner started in 1.75 seconds"
[GIN] 2025/11/09 - 23:24:10 | 200 |  2.447037613s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:11 | 200 |  108.541399ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |  329.016531ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |  101.128138ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |    45.00504ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |  110.523284ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |   64.601734ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |  102.678046ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:28 | 200 |  138.569991ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:28 | 200 |  169.568424ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:37 | 200 |  671.869975ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:37 | 200 |  909.574603ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:37 | 200 |  322.774984ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:38 | 200 |   297.79992ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:38 | 200 |  335.980971ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:47 | 200 |   135.31309ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:48 | 200 |   98.862005ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:50 | 200 |  483.498502ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:51 | 200 |  642.458078ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:57 | 200 |  156.634606ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:57 | 200 |  191.079179ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:57 | 200 |  188.456699ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:04 | 200 |   292.56699ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:05 | 200 |  381.857342ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:05 | 200 |  149.085548ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:05 | 200 |   164.06477ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:05 | 200 |  171.426072ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:07 | 200 |   438.91192ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:07 | 200 |  490.296576ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:08 | 200 |  547.611298ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:08 | 200 |  255.834487ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:08 | 200 |  214.071694ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:08 | 200 |  278.043095ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:08 | 200 |  150.726869ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:09 | 200 |  265.314904ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:13 | 200 |   850.52495ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:14 | 200 |  130.886017ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:14 | 200 |  145.861633ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:20 | 200 |  372.005469ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:21 | 200 |  381.150538ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:56 | 200 |  144.832503ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:56 | 200 |  174.281168ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:57 | 200 |  255.907215ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:57 | 200 |  161.451496ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:58 | 200 |  145.642253ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:58 | 200 |  156.388968ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:58 | 200 |   92.365398ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:59 | 200 |   93.183754ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:12 | 200 |  279.251791ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:12 | 200 |   78.091248ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:13 | 200 |   84.378276ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:16 | 200 |  318.547468ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:16 | 200 |  114.924002ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:16 | 200 |  138.112482ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:17 | 200 |  122.173345ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:17 | 200 |   97.167083ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:22 | 200 |  153.216516ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:22 | 200 |  124.595561ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:22 | 200 |   90.986508ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:22 | 200 |    89.04789ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:30 | 200 |  331.738083ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:30 | 200 |  404.741658ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:30 | 200 |  212.635655ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:31 | 200 |  324.792159ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:31 | 200 |  303.737451ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:31 | 200 |   92.661353ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:37 | 200 |  177.325211ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:37 | 200 |  149.421792ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:38 | 200 |  123.724513ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:40 | 200 |  344.553228ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:41 | 200 |  1.166251001s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:41 | 200 |  1.061250813s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:41 | 200 |  1.158945332s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:41 | 200 |  117.488162ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:42 | 200 |  426.713511ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:42 | 200 |  543.281396ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:42 | 200 |  190.645028ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:42 | 200 |  120.618536ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:43 | 200 |  230.738342ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:44 | 200 |  288.457852ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:46 | 200 |   97.665186ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:47 | 200 |   85.819148ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:58 | 200 |   263.08977ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:58 | 200 |  161.342821ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:58 | 200 |   71.684246ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:58 | 200 |  267.610894ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:59 | 200 |   194.76644ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:08 | 200 |   77.452262ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:08 | 200 |   94.524409ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:09 | 200 |   72.627207ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:10 | 200 |  124.701908ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:18 | 200 |  315.176277ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:18 | 200 |  253.901822ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:18 | 200 |  282.208542ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:19 | 200 |   83.288706ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:26 | 200 |  858.631192ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:26 | 200 |  751.723932ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:27 | 200 |  898.509409ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:27 | 200 |  895.744651ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:28 | 200 |    1.3412544s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:28 | 200 |  1.009849712s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:28 | 200 |  181.111672ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:29 | 200 |  190.156085ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:35 | 200 |  758.237041ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:35 | 200 |  244.817075ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:36 | 200 |   555.30501ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:36 | 200 |  115.051166ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:36 | 200 |   88.341903ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:39 | 200 |  595.489334ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:39 | 200 |  115.399771ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:39 | 200 |   102.82338ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:42 | 200 |  935.729601ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:42 | 200 |  312.820817ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:43 | 200 |  343.767062ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:43 | 200 |  737.122404ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:44 | 200 |  104.954751ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:44 | 200 |  124.470786ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:24 | 200 |  140.920058ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:30 | 200 |  225.643385ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:30 | 200 |  352.564913ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:31 | 200 |   512.91009ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:31 | 200 |  587.297667ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:31 | 200 |  118.750263ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:31 | 200 |  131.757104ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:32 | 200 |   562.05756ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:33 | 200 |  239.635065ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:33 | 200 |  226.320086ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:34 | 200 |  155.886461ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:34 | 200 |  185.752662ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:35 | 200 |  684.962075ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:35 | 200 |  714.395914ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:35 | 200 |  204.914626ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:36 | 200 |  111.893828ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:37 | 200 |  1.000663899s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:37 | 200 |  1.000504092s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:38 | 200 |  1.308870064s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:45 | 200 |  190.978023ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:46 | 200 |  824.229616ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:47 | 200 |  1.163657938s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:47 | 200 |  766.901805ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:47 | 200 |  895.455112ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:48 | 200 |  836.489527ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:48 | 200 |  1.218691558s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:48 | 200 |  433.917899ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:49 | 200 |  831.322894ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:50 | 200 |  214.771019ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:51 | 200 |  200.544429ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:52 | 200 |  449.980348ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:52 | 200 |  105.091014ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:53 | 200 |  144.340327ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:53 | 200 |  165.852541ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:53 | 200 |  161.792741ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:54 | 200 |   322.40052ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:54 | 200 |  382.796821ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:54 | 200 |  528.993643ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:55 | 200 |  355.383473ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:01 | 200 |  187.625749ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:01 | 200 |   89.782304ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:01 | 200 |    92.84916ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:05 | 200 |  148.553959ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:06 | 200 |    566.2762ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:07 | 200 |   687.19358ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:07 | 200 |  214.182453ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:08 | 200 |  938.295827ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:08 | 200 |  578.022438ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:08 | 200 |  161.423784ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:09 | 200 |  205.499468ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:10 | 200 |  182.505171ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:11 | 200 |  182.953534ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:22 | 200 |  229.052639ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:23 | 200 |  256.936583ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:27 | 200 |  280.108275ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:28 | 200 |  189.536816ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:33 | 200 |  253.786707ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:34 | 200 |   217.37646ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:34 | 200 |   84.212767ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:42 | 200 |     354.607ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:43 | 200 |  345.856697ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:43 | 200 |  256.027418ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:43 | 200 |  221.560607ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:44 | 200 |    211.7269ms |       127.0.0.1 | POST     "/api/generate"
time=2025-11-09T23:36:36.035-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:36:36.035-07:00 level=INFO source=images.go:522 msg="total blobs: 6"
time=2025-11-09T23:36:36.035-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:36:36.035-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-09T23:36:36.035-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:36:36.036-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37279"
time=2025-11-09T23:36:36.223-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45311"
time=2025-11-09T23:36:36.406-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44263"
time=2025-11-09T23:36:36.406-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36035"
time=2025-11-09T23:36:36.614-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:36:41 | 200 |      44.163µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:36:41 | 404 |     209.694µs |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:36:41 | 200 |      76.213µs |       127.0.0.1 | HEAD     "/"
time=2025-11-09T23:36:41.539-07:00 level=INFO source=download.go:177 msg="downloading 735af2139dc6 in 3 100 MB part(s)"
time=2025-11-09T23:36:44.759-07:00 level=INFO source=download.go:177 msg="downloading 4b19ac7dd2fb in 1 476 B part(s)"
time=2025-11-09T23:36:45.979-07:00 level=INFO source=download.go:177 msg="downloading 3e2c24001f9e in 1 8.4 KB part(s)"
time=2025-11-09T23:36:47.195-07:00 level=INFO source=download.go:177 msg="downloading 339e884a40f6 in 1 61 B part(s)"
time=2025-11-09T23:36:48.407-07:00 level=INFO source=download.go:177 msg="downloading 74156d92caf6 in 1 490 B part(s)"
[GIN] 2025/11/09 - 23:36:49 | 200 |  8.585129126s |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/11/09 - 23:41:50 | 200 |     280.006µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:49:23.723-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:49:23.724-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-09T23:49:23.725-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:49:23.725-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-09T23:49:23.725-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:49:23.726-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39135"
time=2025-11-09T23:49:24.172-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45471"
time=2025-11-09T23:49:24.380-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44951"
time=2025-11-09T23:49:24.380-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39267"
time=2025-11-09T23:49:24.600-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:49:28 | 200 |      68.589µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:49:28 | 200 |   43.996117ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:51:25 | 200 |     549.903µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:57:30.887-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:57:30.888-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-09T23:57:30.888-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:57:30.888-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-09T23:57:30.888-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:57:30.889-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39649"
time=2025-11-09T23:57:31.081-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42477"
time=2025-11-09T23:57:31.279-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33233"
time=2025-11-09T23:57:31.279-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38685"
time=2025-11-09T23:57:31.775-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:57:35 | 200 |      30.247µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:57:35 | 200 |   48.838042ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:59:32 | 200 |     583.336µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:04:50.076-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:04:50.077-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:04:50.077-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:04:50.077-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-10T00:04:50.077-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:04:50.077-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37637"
time=2025-11-10T00:04:50.277-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 34183"
time=2025-11-10T00:04:50.734-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33941"
time=2025-11-10T00:04:50.734-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 46139"
time=2025-11-10T00:04:50.954-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:04:55 | 200 |      60.343µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:04:55 | 200 |   47.045218ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:06:51 | 200 |     533.272µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:11:04.871-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:11:04.871-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:11:04.872-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:11:04.872-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-10T00:11:04.872-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:11:04.873-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33543"
time=2025-11-10T00:11:05.068-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41769"
time=2025-11-10T00:11:05.256-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44933"
time=2025-11-10T00:11:05.257-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39695"
time=2025-11-10T00:11:05.761-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:11:09 | 200 |      30.878µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:11:09 | 200 |   48.695294ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:13:06 | 200 |     341.592µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:17:42.876-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:17:42.877-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:17:42.877-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:17:42.877-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-10T00:17:42.877-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:17:42.878-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 46165"
time=2025-11-10T00:17:43.279-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33309"
time=2025-11-10T00:17:43.532-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43095"
time=2025-11-10T00:17:43.532-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42959"
time=2025-11-10T00:17:43.775-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:17:47 | 200 |      35.417µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:17:47 | 200 |   55.416225ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:19:45 | 200 |     429.447µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:26:06.164-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:26:06.165-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:26:06.165-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:26:06.165-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-10T00:26:06.165-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:26:06.166-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33069"
time=2025-11-10T00:26:06.384-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 40917"
time=2025-11-10T00:26:06.612-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 34767"
time=2025-11-10T00:26:06.612-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44239"
time=2025-11-10T00:26:06.854-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:26:11 | 200 |      57.438µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:26:11 | 200 |   55.167804ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:28:08 | 200 |     352.923µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:37:04.291-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:37:04.291-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:37:04.291-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:37:04.291-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-10T00:37:04.292-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:37:04.293-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 46083"
time=2025-11-10T00:37:04.521-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33861"
time=2025-11-10T00:37:04.741-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 32951"
time=2025-11-10T00:37:04.741-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36171"
time=2025-11-10T00:37:04.996-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:37:09 | 200 |      97.604µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:37:09 | 200 |   54.694986ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:39:06 | 200 |      399.04µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:47:38.610-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:47:38.611-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:47:38.611-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:47:38.611-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-10T00:47:38.611-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:47:38.612-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39925"
time=2025-11-10T00:47:38.813-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45475"
time=2025-11-10T00:47:39.264-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 40959"
time=2025-11-10T00:47:39.264-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43527"
time=2025-11-10T00:47:39.484-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:47:43 | 200 |      55.204µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:47:43 | 200 |   43.516946ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:49:40 | 200 |      697.49µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:07:38.090-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:07:38.091-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:07:38.092-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:07:38.092-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-10T01:07:38.092-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:07:38.093-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35739"
time=2025-11-10T01:07:38.295-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 46083"
time=2025-11-10T01:07:38.727-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44107"
time=2025-11-10T01:07:38.727-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35777"
time=2025-11-10T01:07:38.947-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:07:43 | 200 |      82.335µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:07:43 | 200 |   46.419097ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:09:40 | 200 |     499.469µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:14:49.042-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:14:49.043-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:14:49.043-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:14:49.043-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-10T01:14:49.043-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:14:49.044-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33101"
time=2025-11-10T01:14:49.258-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45633"
time=2025-11-10T01:14:49.467-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44699"
time=2025-11-10T01:14:49.467-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33941"
time=2025-11-10T01:14:49.957-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:14:54 | 200 |      62.969µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:14:54 | 200 |   46.624243ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:16:50 | 200 |     472.328µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:28:03.675-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42051"
time=2025-11-10T01:28:05.625-07:00 level=INFO source=server.go:215 msg="enabling flash attention"
time=2025-11-10T01:28:05.626-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /home/dan/.ollama-11460/blobs/sha256-735af2139dc652bf01112746474883d79a52fa1c19038265d363e3d42556f7a2 --port 41259"
time=2025-11-10T01:28:05.633-07:00 level=INFO source=server.go:653 msg="loading model" "model layers"=19 requested=-1
time=2025-11-10T01:28:05.633-07:00 level=INFO source=server.go:658 msg="system memory" total="123.6 GiB" free="90.3 GiB" free_swap="0 B"
time=2025-11-10T01:28:05.633-07:00 level=INFO source=server.go:665 msg="gpu memory" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 library=CUDA available="16.0 GiB" free="16.4 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-10T01:28:05.673-07:00 level=INFO source=runner.go:1349 msg="starting ollama engine"
time=2025-11-10T01:28:05.674-07:00 level=INFO source=runner.go:1384 msg="Server listening on 127.0.0.1:41259"
time=2025-11-10T01:28:05.676-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:28:06.034-07:00 level=INFO source=ggml.go:136 msg="" architecture=gemma3 file_type=Q8_0 name="" description="" num_tensors=236 num_key_values=37
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-874c91aa-3bb2-54a0-534f-860241e77353
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-10T01:28:06.363-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-10T01:28:07.084-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:28:07.293-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:28:07.293-07:00 level=INFO source=ggml.go:482 msg="offloading 18 repeating layers to GPU"
time=2025-11-10T01:28:07.294-07:00 level=INFO source=ggml.go:489 msg="offloading output layer to GPU"
time=2025-11-10T01:28:07.294-07:00 level=INFO source=ggml.go:494 msg="offloaded 19/19 layers to GPU"
time=2025-11-10T01:28:07.296-07:00 level=INFO source=device.go:212 msg="model weights" device=CUDA0 size="271.9 MiB"
time=2025-11-10T01:28:07.296-07:00 level=INFO source=device.go:217 msg="model weights" device=CPU size="170.0 MiB"
time=2025-11-10T01:28:07.296-07:00 level=INFO source=device.go:223 msg="kv cache" device=CUDA0 size="27.0 MiB"
time=2025-11-10T01:28:07.296-07:00 level=INFO source=device.go:234 msg="compute graph" device=CUDA0 size="155.5 MiB"
time=2025-11-10T01:28:07.296-07:00 level=INFO source=device.go:239 msg="compute graph" device=CPU size="1.2 MiB"
time=2025-11-10T01:28:07.296-07:00 level=INFO source=device.go:244 msg="total memory" size="625.6 MiB"
time=2025-11-10T01:28:07.296-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-10T01:28:07.296-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-10T01:28:07.351-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
time=2025-11-10T01:28:08.614-07:00 level=INFO source=server.go:1289 msg="llama runner started in 2.98 seconds"
[GIN] 2025/11/10 - 01:28:10 | 200 |  7.275067235s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:11 | 200 |  8.619043861s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:14 | 200 | 10.548508341s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:15 | 200 | 12.024628277s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:17 | 200 | 13.636923288s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:20 | 200 | 10.441007978s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:22 | 200 | 11.064511527s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:25 | 200 | 11.361507956s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:27 | 200 | 11.683607323s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:29 | 200 | 11.067738094s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:30 | 200 | 10.114348215s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:32 | 200 |  9.896557467s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:35 | 200 |  9.420679713s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:37 | 200 | 10.234639568s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:40 | 200 | 11.293928222s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:42 | 200 | 11.508602483s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:44 | 200 | 11.530881915s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:46 | 200 |  8.976558481s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:50 | 200 |  8.630213292s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:52 | 200 |  7.312215362s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:54 | 200 |  8.000043008s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:55 | 200 |  7.331417133s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:57 | 200 |  8.508559264s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:59 | 200 |  8.816441162s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:04 | 200 | 11.876018897s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:08 | 200 | 13.238047358s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:11 | 200 | 14.701471388s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:14 | 200 |  14.31183782s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:17 | 200 | 13.686474415s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:19 | 200 | 14.713569158s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:21 | 200 | 10.827169644s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:23 | 200 | 11.882660251s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:25 | 200 |  8.848818512s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:28 | 200 |  9.060323498s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:30 | 200 |  10.38308321s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:31 | 200 |  7.995288831s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:34 | 200 | 10.416528887s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:36 | 200 | 10.779608478s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:38 | 200 | 10.081424076s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:40 | 200 |   8.42263074s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:42 | 200 |  6.652904078s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:44 | 200 |  2.142204307s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:48 | 200 |  5.582137462s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:50 | 200 |  6.604155487s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:51 | 200 |  5.933154973s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:54 | 200 |   8.19262421s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:55 | 200 |  9.229953328s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:57 | 200 |  6.503465972s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:59 | 200 |  7.600976014s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:01 | 200 |  8.525375392s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:04 | 200 |  9.928154425s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:06 | 200 | 10.699598648s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:08 | 200 | 10.974107561s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:08 | 200 |   9.38957926s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:10 | 200 |  8.950197258s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:13 | 200 |  8.962662374s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:15 | 200 |  8.846256576s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:16 | 200 |  7.901419061s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:18 | 200 |   4.24799445s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:20 | 200 |  4.762527337s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:24 | 200 |  3.255766449s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:25 | 200 |  2.861758577s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:28 | 200 |  4.989019747s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:30 | 200 |  5.269699393s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:32 | 200 |  6.173090366s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:35 | 200 |  7.631173007s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:37 | 200 |  7.725163474s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:40 | 200 | 10.293443778s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:43 | 200 |  8.789255136s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:45 | 200 | 10.586157703s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:47 | 200 | 10.821593168s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:49 | 200 |  5.332791237s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:52 | 200 |  7.736028324s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:54 | 200 |  6.027157162s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:56 | 200 |  6.804977741s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:59 | 200 |  7.245209523s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:01 | 200 |  5.731953183s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:03 | 200 |  4.183717375s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:06 | 200 |  4.347634447s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:08 | 200 |  6.335495655s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:11 | 200 |  7.803760184s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:13 | 200 |  5.354849702s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:15 | 200 |  6.504604407s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:24 | 200 |   3.50451568s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:29 | 200 |  2.016508144s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:33 | 200 |  2.704611323s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:34 | 200 |  1.942163398s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:37 | 200 |  3.571089249s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:54 | 200 |  3.573217966s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:56 | 200 |  3.580723257s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:59 | 200 |  5.150083596s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:02 | 200 |  4.969893418s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:04 | 200 |  4.176439651s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:07 | 200 |  7.516516321s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:10 | 200 |  8.227086187s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:12 | 200 |  8.379637143s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:16 | 200 | 11.491349611s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:24 | 200 | 18.258258036s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:26 | 200 | 13.782457078s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:29 | 200 | 16.084980124s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:31 | 200 | 17.084237545s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:33 | 200 | 17.142031287s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:35 | 200 | 11.543208549s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:39 | 200 | 12.640229891s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:41 | 200 | 11.948963433s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:43 | 200 | 11.396359343s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:46 | 200 |  12.93424864s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:49 | 200 | 13.063927981s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:51 | 200 | 12.452708194s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:54 | 200 | 13.201995493s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:56 | 200 | 13.511298452s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:59 | 200 |  12.34928894s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:02 | 200 | 13.132027808s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:06 | 200 | 14.747344902s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:08 | 200 | 13.942534696s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:10 | 200 | 14.020769605s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:12 | 200 | 13.120711798s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:13 | 200 | 10.933618253s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:15 | 200 |  8.870332763s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:17 | 200 |  8.854549486s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:20 | 200 |  8.834073218s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:23 | 200 | 10.491230285s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:25 | 200 | 11.151696998s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:26 | 200 | 11.013343196s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:28 | 200 |  9.357248928s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:29 | 200 |  9.385382569s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:31 | 200 |  8.422779084s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:34 | 200 |   9.47906781s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:36 | 200 |  8.487272081s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:40 | 200 | 10.733996283s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:42 | 200 | 11.979847703s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:45 | 200 | 12.954314327s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:47 | 200 |  8.761145815s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:50 | 200 |  9.720785897s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:52 | 200 | 11.605905983s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:55 | 200 | 11.723517715s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:58 | 200 | 12.986329041s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:01 | 200 | 13.655907348s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:03 | 200 | 13.716261756s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:06 | 200 | 12.837000025s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:08 | 200 | 13.083036466s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:11 | 200 | 13.054124993s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:13 | 200 | 12.147706277s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:15 | 200 | 11.683376468s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:18 | 200 | 12.268165757s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:21 | 200 | 12.770565337s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:24 | 200 | 12.613761951s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:27 | 200 | 12.884257235s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:29 | 200 | 13.249908981s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:31 | 200 | 13.136975971s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:33 | 200 |   12.5071547s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:36 | 200 | 12.653350995s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:38 | 200 | 11.467101242s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:41 | 200 | 12.006522882s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:43 | 200 | 12.096667393s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:46 | 200 | 12.242339685s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:47 | 200 |  10.96281665s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:49 | 200 | 10.890523291s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:52 | 200 | 10.430652284s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:55 | 200 | 10.866877315s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:58 | 200 | 11.550691461s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:59 | 200 | 11.339477227s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:02 | 200 | 12.355611785s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:04 | 200 | 12.291139668s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:07 | 200 |  12.00072421s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:09 | 200 | 11.029619178s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:10 | 200 | 10.995777123s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:12 | 200 |  9.668465167s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:14 | 200 |  9.731869968s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:16 | 200 |  9.109192521s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:17 | 200 |  8.515818334s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:19 | 200 |  8.444713494s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:20 | 200 |  7.952023294s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:21 | 200 |  6.805055538s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:22 | 200 |  5.730518726s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:23 | 200 |  5.472613342s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:24 | 200 |  5.022045123s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:25 | 200 |  5.019828752s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:26 | 200 |  4.005992979s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:47 | 200 |  4.831395226s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:49 | 200 |  6.024201065s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:51 | 200 |  8.837142246s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:53 | 200 | 10.932244849s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:55 | 200 | 12.959624513s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:58 | 200 | 11.702639691s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:00 | 200 | 11.412337413s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:03 | 200 | 11.528523091s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:04 | 200 |  10.05330202s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:06 | 200 | 10.797707708s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:11 | 200 | 12.372779756s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:13 | 200 | 12.714480314s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:16 | 200 | 13.417632654s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:18 | 200 | 14.304065075s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:21 | 200 | 14.270639652s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:25 | 200 | 14.004788753s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:28 | 200 | 13.922159472s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:30 | 200 | 13.388461622s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:33 | 200 | 14.439930034s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:36 | 200 | 10.001122281s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:39 | 200 | 12.543619615s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:41 | 200 | 13.412214829s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:43 | 200 |  13.46118622s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:47 | 200 |  13.41260995s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:49 | 200 | 13.232876649s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:52 | 200 | 12.542985531s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:53 | 200 | 11.858460077s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:56 | 200 | 11.837225902s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:58 | 200 | 11.344693766s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:01 | 200 | 11.666642838s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:03 | 200 | 11.245938683s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:05 | 200 | 11.987866286s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:08 | 200 | 12.294652865s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:12 | 200 | 13.626874749s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:14 | 200 | 13.052911628s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:17 | 200 | 13.341963025s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:20 | 200 | 14.205303548s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:22 | 200 | 13.954561593s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:25 | 200 | 12.860554186s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:28 | 200 | 13.525817802s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:30 | 200 | 12.551722266s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:32 | 200 | 11.975758321s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:34 | 200 | 12.071666062s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:38 | 200 | 12.130355238s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:40 | 200 | 11.740280854s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:41 | 200 | 11.205558684s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:43 | 200 | 11.360146884s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:45 | 200 | 10.605655489s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:48 | 200 |  9.901666021s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:50 | 200 |  9.022786083s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:52 | 200 | 11.075493585s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:55 | 200 | 11.513406097s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:57 | 200 | 11.266814063s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:59 | 200 | 11.375223151s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:01 | 200 |  11.47380409s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:03 | 200 | 10.795765805s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:06 | 200 | 10.986178549s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:08 | 200 |  10.74698092s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:11 | 200 |  11.30480841s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:13 | 200 | 11.362048487s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:16 | 200 | 13.011218003s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:19 | 200 | 12.695189653s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:22 | 200 | 13.874689383s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:25 | 200 | 13.961540302s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:28 | 200 |  14.49770179s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:29 | 200 | 12.697317716s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:33 | 200 | 14.209640183s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:35 | 200 | 13.325118586s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:38:36.919-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 01:38:36 | 500 |  3.006401185s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:36 | 500 | 11.499366429s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:38:36.938-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 01:38:36 | 500 |  8.623360846s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:36 | 500 |  1.141521146s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:36 | 500 |  7.106683119s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:38:37.461-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
time=2025-11-10T01:38:37.680-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
time=2025-11-10T01:39:33.156-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:39:33.157-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:39:33.157-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:39:33.157-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-10T01:39:33.157-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:39:33.158-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41429"
time=2025-11-10T01:39:33.352-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36237"
time=2025-11-10T01:39:33.537-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39115"
time=2025-11-10T01:39:33.537-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37807"
time=2025-11-10T01:39:34.047-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:39:35 | 200 |      36.569µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:39:35 | 200 |   45.970203ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:40:23 | 200 |     641.145µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:40:52.588-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44377"
time=2025-11-10T01:40:53.816-07:00 level=INFO source=server.go:215 msg="enabling flash attention"
time=2025-11-10T01:40:53.816-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /home/dan/.ollama-11460/blobs/sha256-735af2139dc652bf01112746474883d79a52fa1c19038265d363e3d42556f7a2 --port 32929"
time=2025-11-10T01:40:53.817-07:00 level=INFO source=server.go:653 msg="loading model" "model layers"=19 requested=-1
time=2025-11-10T01:40:53.817-07:00 level=INFO source=server.go:658 msg="system memory" total="123.6 GiB" free="100.8 GiB" free_swap="0 B"
time=2025-11-10T01:40:53.817-07:00 level=INFO source=server.go:665 msg="gpu memory" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 library=CUDA available="20.5 GiB" free="20.9 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-10T01:40:53.833-07:00 level=INFO source=runner.go:1349 msg="starting ollama engine"
time=2025-11-10T01:40:53.833-07:00 level=INFO source=runner.go:1384 msg="Server listening on 127.0.0.1:32929"
time=2025-11-10T01:40:53.841-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:40:53.891-07:00 level=INFO source=ggml.go:136 msg="" architecture=gemma3 file_type=Q8_0 name="" description="" num_tensors=236 num_key_values=37
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-874c91aa-3bb2-54a0-534f-860241e77353
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-10T01:40:54.714-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-10T01:40:56.243-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:40:56.440-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:40:56.441-07:00 level=INFO source=ggml.go:482 msg="offloading 18 repeating layers to GPU"
time=2025-11-10T01:40:56.441-07:00 level=INFO source=ggml.go:489 msg="offloading output layer to GPU"
time=2025-11-10T01:40:56.441-07:00 level=INFO source=ggml.go:494 msg="offloaded 19/19 layers to GPU"
time=2025-11-10T01:40:56.448-07:00 level=INFO source=device.go:212 msg="model weights" device=CUDA0 size="271.9 MiB"
time=2025-11-10T01:40:56.448-07:00 level=INFO source=device.go:217 msg="model weights" device=CPU size="170.0 MiB"
time=2025-11-10T01:40:56.448-07:00 level=INFO source=device.go:223 msg="kv cache" device=CUDA0 size="27.0 MiB"
time=2025-11-10T01:40:56.448-07:00 level=INFO source=device.go:234 msg="compute graph" device=CUDA0 size="155.5 MiB"
time=2025-11-10T01:40:56.448-07:00 level=INFO source=device.go:239 msg="compute graph" device=CPU size="1.2 MiB"
time=2025-11-10T01:40:56.448-07:00 level=INFO source=device.go:244 msg="total memory" size="625.6 MiB"
time=2025-11-10T01:40:56.448-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-10T01:40:56.448-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-10T01:40:56.456-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
time=2025-11-10T01:40:57.215-07:00 level=INFO source=server.go:1289 msg="llama runner started in 3.40 seconds"
[GIN] 2025/11/10 - 01:40:58 | 200 |  5.748025954s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:40:59 | 200 |  6.594783755s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:40:59 | 200 |  1.215890099s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:40:59 | 200 |  756.903159ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:13 | 200 |  499.535668ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:13 | 200 |  565.641754ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:07 | 200 |  2.098371544s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:09 | 200 |  1.934621503s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:13 | 200 |  4.212486385s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:19 | 200 |  6.744192432s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:24 | 200 | 10.019892702s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:28 | 200 | 12.199521398s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:33 | 200 | 16.045351363s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:37 | 200 | 18.231123775s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:41 | 200 | 18.834438577s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:46 | 200 | 17.818837124s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:51 | 200 | 20.759349501s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:55 | 200 | 22.075760784s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:00 | 200 | 22.604018243s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:06 | 200 | 25.035584796s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:11 | 200 |   24.4737998s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:16 | 200 | 24.246057989s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:21 | 200 | 25.700483708s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:27 | 200 | 26.758674881s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:33 | 200 | 26.018757641s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:36 | 200 | 24.499611602s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:42 | 200 | 26.252103204s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:46 | 200 | 24.531656807s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:50 | 200 | 22.338544199s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:55 | 200 | 22.555942391s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:02 | 200 | 25.156444516s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:07 | 200 | 23.464484558s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:10 | 200 | 23.427949533s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:14 | 200 | 24.185397918s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:19 | 200 | 23.187185249s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:24 | 200 |  21.15967194s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:28 | 200 | 21.166134409s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:33 | 200 | 22.435118939s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:37 | 200 | 22.506180134s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:41 | 200 | 22.394098824s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:47 | 200 |  22.53766339s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:50 | 200 | 21.321701136s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:54 | 200 | 21.515283521s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:58 | 200 | 20.974188467s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:03 | 200 | 21.276828239s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:08 | 200 | 20.612078623s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:11 | 200 | 20.452019188s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:14 | 200 | 19.258427574s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:17 | 200 | 18.796787325s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:22 | 200 | 18.637188072s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:28 | 200 | 19.865993857s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:33 | 200 | 22.240997716s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:38 | 200 | 23.389040983s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:45 | 200 | 27.760262269s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:52 | 200 | 29.839296483s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:57 | 200 | 28.680264232s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:59 | 200 | 26.020039898s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:05 | 200 |  26.35593743s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:08 | 200 | 22.009018037s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:12 | 200 | 19.753750568s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:17 | 200 | 19.926651047s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:23 | 200 | 23.397176802s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:28 | 200 | 22.489696435s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:34 | 200 | 25.823063715s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:38 | 200 | 25.224241415s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:46 | 200 | 29.032646257s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:51 | 200 |  27.78655913s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:54 | 200 | 26.365413152s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:57 | 200 | 22.742698175s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:59 | 200 | 20.069156971s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:01 | 200 | 15.330378759s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:03 | 200 | 12.113283995s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:05 | 200 | 10.382160408s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:07 | 200 | 10.122755813s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:09 | 200 |  9.469739324s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:11 | 200 |  8.721025543s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:12 | 200 |  8.242533937s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:12 | 200 |  7.325436881s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:31 | 200 |  8.076728749s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:34 | 200 | 10.622926713s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:42 | 200 | 18.974176921s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:46 | 200 | 20.919788523s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:49 | 200 | 24.553731995s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:55 | 200 |  23.68661646s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:58 | 200 | 23.674264039s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:02 | 200 | 19.103302611s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:09 | 200 | 22.130688999s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:15 | 200 | 24.719481788s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:20 | 200 |   24.7305741s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:26 | 200 | 25.471003232s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:31 | 200 | 23.910546095s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:37 | 200 |  27.42859563s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:40 | 200 | 25.055995899s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:45 | 200 | 24.363847418s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:48 | 200 |    21.791293s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:54 | 200 | 23.280937086s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:59 | 200 | 21.968833146s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:00 | 200 | 19.016389903s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:03 | 200 | 18.114882218s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:07 | 200 | 18.861939737s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:12 | 200 | 16.918517034s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:19 | 200 | 19.924960699s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:22 | 200 | 22.124569065s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:28 | 200 | 24.017634353s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:34 | 200 | 26.050404196s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:41 | 200 | 28.857787031s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:47 | 200 | 27.743733865s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:50 | 200 | 27.200277374s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:53 | 200 | 24.407142117s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:56 | 200 | 22.011809496s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:01 | 200 | 18.800091635s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:07 | 200 | 20.477667068s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:12 | 200 | 21.155068573s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:14 | 200 | 20.914802091s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:18 | 200 | 21.350530095s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:22 | 200 | 21.197274004s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:27 | 200 | 19.840124065s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:31 | 200 | 19.662354971s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:35 | 200 | 20.780699344s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:40 | 200 | 21.104235046s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:43 | 200 | 20.725652343s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:49 | 200 | 21.709626517s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:53 | 200 | 21.628815379s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:58 | 200 | 22.495892167s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:02 | 200 | 21.861432751s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:06 | 200 |  22.40981785s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:11 | 200 | 20.871506007s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:15 | 200 | 21.119974354s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:19 | 200 | 20.463926841s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:23 | 200 | 20.674357972s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:26 | 200 | 19.545363229s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:32 | 200 |  20.34864824s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:39 | 200 | 23.614355495s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:42 | 200 | 23.219905033s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:47 | 200 | 23.403607554s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:54 | 200 | 27.372190776s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:59 | 200 | 26.593122649s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:03 | 200 | 23.993430094s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:10 | 200 | 27.738462979s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:17 | 200 | 29.714286953s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:21 | 200 | 26.406155081s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:27 | 200 | 28.250998414s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:32 | 200 | 28.721414195s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:35 | 200 | 24.176170128s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:41 | 200 | 23.899215182s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:43 | 200 | 21.764797234s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:45 | 200 | 17.108957295s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:48 | 200 |  16.03260503s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:50 | 200 | 14.703542482s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:55 | 200 | 14.299770246s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:01 | 200 | 17.383937054s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:06 | 200 | 20.722003654s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:12 | 200 | 23.566351905s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:17 | 200 | 26.806854925s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:20 | 200 | 23.948599029s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:23 | 200 | 22.189936045s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:29 | 200 | 22.849626087s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:33 | 200 | 20.611155839s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:37 | 200 | 19.394209265s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:42 | 200 | 21.368528115s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:45 | 200 | 21.863545782s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:48 | 200 | 19.347559954s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:54 | 200 | 20.754078027s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:59 | 200 | 22.130486855s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:05 | 200 | 22.771567161s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:09 | 200 | 24.130713815s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:13 | 200 |  23.84565365s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:16 | 200 | 21.389917238s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:23 | 200 | 23.451256051s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:29 | 200 | 23.393417184s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:35 | 200 | 25.574767656s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:42 | 200 | 29.359840331s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:49 | 200 | 31.750932721s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:54 | 200 | 29.112040212s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:58 | 200 | 25.022899382s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:03 | 200 | 24.199010913s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:07 | 200 | 19.519182465s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:10 | 200 | 15.849835108s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:14 | 200 | 15.395531309s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:18 | 200 | 11.624052309s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:23 | 200 | 12.644107552s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:26 | 200 | 12.115266851s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:32 | 200 | 13.473882044s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:37 | 200 | 15.858003118s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:40 | 200 |  13.96927261s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:43 | 200 | 15.618214049s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:48 | 200 | 13.393041368s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:53 | 200 | 16.018460666s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:58 | 200 | 17.263702164s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:04 | 200 | 17.634956047s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:10 | 200 | 17.064037046s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:14 | 200 | 15.156093008s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:18 | 200 | 13.398785591s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:25 | 200 | 14.347999389s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:30 | 200 | 13.345438827s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:36 | 200 | 12.566199892s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:40 | 200 |  10.93256494s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:44 | 200 | 13.814569275s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:50 | 200 | 14.522099089s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:55 | 200 |  13.98165989s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:00 | 200 | 10.327093688s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:04 | 200 |  8.260707903s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:08 | 200 |  6.771490243s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:13 | 200 |  8.288934306s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:17 | 200 |  9.414455553s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:21 | 200 | 12.275162304s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:25 | 200 | 10.086730739s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:31 | 200 | 10.925552016s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:36 | 200 | 10.327185823s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:40 | 200 | 12.796258307s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:44 | 200 | 11.326228379s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:49 | 200 |  9.757963586s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:54 | 200 |  8.556270588s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:59 | 200 |  7.188733102s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:04 | 200 |  9.180472865s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:09 | 200 | 10.797423875s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:16 | 200 | 11.859393996s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:21 | 200 |  10.80022168s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:27 | 200 |  9.210841371s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:31 | 200 |  8.955969599s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:34 | 200 | 10.275093858s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:36 | 200 |  9.496826955s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:40 | 200 |   8.65982865s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:44 | 200 |  6.843557808s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:49 | 200 |  8.455851754s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:54 | 200 | 10.198171263s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:58 | 200 |  8.407005177s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:02 | 200 |  6.066082064s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:08 | 200 |  5.475502417s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:12 | 200 |  8.525753695s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:16 | 200 |   6.74964952s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:24 | 200 |  9.346038685s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:31 | 200 | 14.410098589s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:35 | 200 | 13.186685024s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:41 | 200 | 12.944196808s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:46 | 200 | 11.129551706s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:49 | 200 |  12.06049613s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:54 | 200 | 12.827926283s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:01 | 200 | 12.265883056s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:06 | 200 | 16.133713975s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:10 | 200 | 14.972697028s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:14 | 200 | 13.459276782s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:19 | 200 | 12.083684268s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:23 | 200 |    10.365182s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:27 | 200 |  8.944520325s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:33 | 200 |  8.317783914s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:40 | 200 |  9.100400214s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:46 | 200 |  7.649519007s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:50 | 200 |  9.024475726s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:54 | 200 | 11.269400498s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:58 | 200 |  8.874286696s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:07 | 200 | 17.196887268s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:12 | 200 | 15.652255298s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:17 | 200 | 18.147267864s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:21 | 200 | 18.235373266s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:24 | 200 |  15.57974542s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:30 | 200 | 15.220468361s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:35 | 200 | 17.612272422s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:39 | 200 | 17.185203331s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:42 | 200 | 14.161674434s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:46 | 200 | 11.446192165s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:50 | 200 |  3.139359874s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:26 | 200 |  7.584820167s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:30 | 200 | 11.099936216s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:33 | 200 |  12.87186649s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:37 | 200 | 16.149542333s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:40 | 200 | 20.467061142s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:44 | 200 | 17.947786689s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:49 | 200 | 18.771420784s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:54 | 200 | 20.883032842s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:57 | 200 | 20.665639186s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:05 | 200 | 24.225678711s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:08 | 200 | 23.536531422s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:11 | 200 |  22.12220925s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:14 | 200 | 19.831039348s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:16 | 200 |  18.24382392s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:20 | 200 | 15.035766511s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:24 | 200 | 15.842599262s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:35 | 200 | 23.112592948s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:39 | 200 |  21.93440126s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:44 | 200 | 22.540380781s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:47 | 200 | 21.672358056s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:52 | 200 | 19.533878698s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:57 | 200 | 20.859927576s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:02 | 200 | 21.822547695s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:06 | 200 | 22.086019459s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:11 | 200 | 23.600459582s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:15 | 200 | 23.275045766s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:19 | 200 | 21.368167484s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:24 | 200 | 22.134687305s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:29 | 200 | 22.755971377s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:34 | 200 | 22.042372502s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:40 | 200 | 24.510211166s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:46 | 200 | 26.292583353s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:51 | 200 | 26.435905975s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:57 | 200 | 27.408813741s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:04 | 200 | 30.221662073s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:10 | 200 | 30.211169156s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:15 | 200 | 28.539754844s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:20 | 200 | 27.726090374s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:25 | 200 | 26.858556883s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:30 | 200 | 25.189309835s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:34 | 200 | 23.713281568s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:37 | 200 | 21.540765229s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:42 | 200 | 22.192194864s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:49 | 200 | 23.598771255s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:53 | 200 | 22.851732422s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:55 | 200 | 20.539369583s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:57 | 200 | 19.400769674s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:01 | 200 | 17.751591081s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:03 | 200 |  14.49372868s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:07 | 200 | 14.187414366s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:10 | 200 |  14.87980208s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:17 | 200 |  19.55772279s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:21 | 200 | 20.396478744s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:24 | 200 | 21.067736898s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:27 | 200 | 19.818040106s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:30 | 200 | 18.320129523s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:36 | 200 | 18.804825561s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:40 | 200 | 18.567402994s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:43 | 200 | 18.433067089s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:46 | 200 |  17.65465958s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:49 | 200 | 19.171916329s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:52 | 200 | 16.001299384s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:56 | 200 | 15.467763097s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:06:59.952-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:06:59 | 500 | 13.410441316s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:06:59.969-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:06:59 | 500 |  8.149777032s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:07:00.019-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:07:00 | 500 |  6.924251223s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:07:00 | 200 | 16.369959925s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:07:58.176-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11460 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11460 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T02:07:58.177-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T02:07:58.177-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T02:07:58.177-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11460 (version 0.12.9)"
time=2025-11-10T02:07:58.177-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T02:07:58.178-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44665"
time=2025-11-10T02:07:58.378-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44819"
time=2025-11-10T02:07:58.562-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43877"
time=2025-11-10T02:07:58.562-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33321"
time=2025-11-10T02:07:58.777-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 02:08:00 | 200 |      46.307µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 02:08:00 | 200 |   48.392951ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 02:08:48 | 200 |     531.167µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T02:09:18.485-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42373"
time=2025-11-10T02:09:19.244-07:00 level=INFO source=server.go:215 msg="enabling flash attention"
time=2025-11-10T02:09:19.245-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /home/dan/.ollama-11460/blobs/sha256-735af2139dc652bf01112746474883d79a52fa1c19038265d363e3d42556f7a2 --port 34709"
time=2025-11-10T02:09:19.245-07:00 level=INFO source=server.go:653 msg="loading model" "model layers"=19 requested=-1
time=2025-11-10T02:09:19.245-07:00 level=INFO source=server.go:658 msg="system memory" total="123.6 GiB" free="102.4 GiB" free_swap="0 B"
time=2025-11-10T02:09:19.245-07:00 level=INFO source=server.go:665 msg="gpu memory" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 library=CUDA available="21.7 GiB" free="22.1 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-10T02:09:19.258-07:00 level=INFO source=runner.go:1349 msg="starting ollama engine"
time=2025-11-10T02:09:19.258-07:00 level=INFO source=runner.go:1384 msg="Server listening on 127.0.0.1:34709"
time=2025-11-10T02:09:19.268-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:19.311-07:00 level=INFO source=ggml.go:136 msg="" architecture=gemma3 file_type=Q8_0 name="" description="" num_tensors=236 num_key_values=37
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-874c91aa-3bb2-54a0-534f-860241e77353
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-10T02:09:20.165-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-10T02:09:21.742-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:21.968-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:21.968-07:00 level=INFO source=ggml.go:482 msg="offloading 18 repeating layers to GPU"
time=2025-11-10T02:09:21.968-07:00 level=INFO source=ggml.go:489 msg="offloading output layer to GPU"
time=2025-11-10T02:09:21.968-07:00 level=INFO source=ggml.go:494 msg="offloaded 19/19 layers to GPU"
time=2025-11-10T02:09:21.970-07:00 level=INFO source=device.go:212 msg="model weights" device=CUDA0 size="271.9 MiB"
time=2025-11-10T02:09:21.970-07:00 level=INFO source=device.go:217 msg="model weights" device=CPU size="170.0 MiB"
time=2025-11-10T02:09:21.970-07:00 level=INFO source=device.go:223 msg="kv cache" device=CUDA0 size="27.0 MiB"
time=2025-11-10T02:09:21.970-07:00 level=INFO source=device.go:234 msg="compute graph" device=CUDA0 size="155.5 MiB"
time=2025-11-10T02:09:21.970-07:00 level=INFO source=device.go:239 msg="compute graph" device=CPU size="1.2 MiB"
time=2025-11-10T02:09:21.970-07:00 level=INFO source=device.go:244 msg="total memory" size="625.6 MiB"
time=2025-11-10T02:09:21.970-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-10T02:09:21.970-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-10T02:09:21.998-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
time=2025-11-10T02:09:22.751-07:00 level=INFO source=server.go:1289 msg="llama runner started in 3.51 seconds"
[GIN] 2025/11/10 - 02:09:24 | 200 |  6.158075077s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:25 | 200 |  747.962472ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:38 | 200 |  662.451791ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:38 | 200 |  563.230769ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:20 | 200 |  1.219944588s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:22 | 200 |  1.575238954s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:23 | 200 |  1.153997895s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:29 | 200 |  509.072136ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:30 | 200 |  781.471878ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:30 | 200 |  1.253982845s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:31 | 200 |  832.817306ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:15 | 200 |  1.640928195s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:18 | 200 |  2.979313468s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:20 | 200 |  2.587213643s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:34 | 200 |  1.771795082s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:36 | 200 |  2.006856676s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:38 | 200 |  1.962726999s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:20 | 200 |  8.517048756s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:28 | 200 | 15.313075724s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:33 | 200 | 19.686254177s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:37 | 200 | 23.811716608s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:40 | 200 | 25.080303646s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:45 | 200 | 29.822276433s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:50 | 200 | 34.513996344s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:56 | 200 | 37.977821996s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:00 | 200 |  40.40205824s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:06.426-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:06 | 500 |  45.08780369s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:06 | 200 | 46.918341045s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:08.680-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:08 | 500 | 45.047764316s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:08 | 500 | 45.051322321s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:09 | 500 |  45.04599926s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:09.964-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
time=2025-11-10T02:13:11.572-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:12 | 500 | 45.248339782s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:14 | 500 | 45.048711395s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:14.461-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:16 | 500 | 45.049625808s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:16.405-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:20 | 200 |  46.01285374s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:23 | 200 | 45.442262693s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:27 | 200 | 46.389168338s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:31 | 200 | 45.171036719s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:35 | 200 | 44.346883567s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:39 | 200 | 42.315955611s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:42 | 200 | 41.782397499s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:47 | 200 | 41.356904066s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:52 | 200 | 45.158074613s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:54 | 500 | 45.052652132s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:59 | 200 | 23.956610473s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:05 | 200 | 26.584264336s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:11 | 200 | 28.023616921s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:16 | 200 | 31.294615552s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.453-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 |  4.079272689s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.454-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 |  7.984821849s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.458-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 | 15.503563999s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:21 | 200 | 34.118760217s |       127.0.0.1 | POST     "/api/generate"
