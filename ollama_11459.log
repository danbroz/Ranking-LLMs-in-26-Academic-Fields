time=2025-11-09T23:10:39.247-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:0 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:10:39.248-07:00 level=INFO source=images.go:522 msg="total blobs: 0"
time=2025-11-09T23:10:39.248-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:10:39.248-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-09T23:10:39.248-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:10:39.248-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41451"
time=2025-11-09T23:10:39.431-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39967"
time=2025-11-09T23:10:39.608-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 40723"
time=2025-11-09T23:10:39.608-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 34775"
time=2025-11-09T23:10:40.100-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-229ab403-fd4a-7526-7742-befdb34573e4 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:05:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:10:44 | 200 |      82.885µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:10:44 | 404 |     147.127µs |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:10:44 | 200 |      17.242µs |       127.0.0.1 | HEAD     "/"
time=2025-11-09T23:10:44.760-07:00 level=INFO source=download.go:177 msg="downloading f535f83ec568 in 3 100 MB part(s)"
time=2025-11-09T23:10:47.973-07:00 level=INFO source=download.go:177 msg="downloading fbacade46b4d in 1 68 B part(s)"
time=2025-11-09T23:10:49.213-07:00 level=INFO source=download.go:177 msg="downloading d502d55c1d60 in 1 675 B part(s)"
time=2025-11-09T23:10:50.428-07:00 level=INFO source=download.go:177 msg="downloading 58d1e17ffe51 in 1 11 KB part(s)"
time=2025-11-09T23:10:51.643-07:00 level=INFO source=download.go:177 msg="downloading f02dd72bb242 in 1 59 B part(s)"
time=2025-11-09T23:10:52.873-07:00 level=INFO source=download.go:177 msg="downloading b0f58c4c1a3c in 1 561 B part(s)"
[GIN] 2025/11/09 - 23:10:54 | 200 |  9.834745548s |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/11/09 - 23:24:06 | 200 |     467.166µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:24:08.478-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42717"
llama_model_loader: loaded meta data with 33 key-value pairs and 272 tensors from /home/dan/.ollama-11459/blobs/sha256-f535f83ec568d040f88ddc04a199fa6da90923bbb41d4dcaed02caa924d6ef57 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Smollm2 135M 8k Lc100K Mix1 Ep2
llama_model_loader: - kv   3:                       general.organization str              = HuggingFaceTB
llama_model_loader: - kv   4:                           general.finetune str              = 8k-lc100k-mix1-ep2
llama_model_loader: - kv   5:                           general.basename str              = smollm2
llama_model_loader: - kv   6:                         general.size_label str              = 135M
llama_model_loader: - kv   7:                            general.license str              = apache-2.0
llama_model_loader: - kv   8:                          general.languages arr[str,1]       = ["en"]
llama_model_loader: - kv   9:                          llama.block_count u32              = 30
llama_model_loader: - kv  10:                       llama.context_length u32              = 8192
llama_model_loader: - kv  11:                     llama.embedding_length u32              = 576
llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 1536
llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 9
llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 3
llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 100000.000000
llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  17:                          general.file_type u32              = 1
llama_model_loader: - kv  18:                           llama.vocab_size u32              = 49152
llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 64
llama_model_loader: - kv  20:            tokenizer.ggml.add_space_prefix bool             = false
llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = smollm
llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,49152]   = ["<|endoftext|>", "<|im_start|>", "<|...
llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,49152]   = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...
llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,48900]   = ["Ġ t", "Ġ a", "i n", "h e", "Ġ Ġ...
llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 1
llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 2
llama_model_loader: - kv  29:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  30:            tokenizer.ggml.padding_token_id u32              = 2
llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {% for message in messages %}{% if lo...
llama_model_loader: - kv  32:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type  f16:  211 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = F16
print_info: file size   = 256.63 MiB (16.00 BPW) 
load: printing all EOG tokens:
load:   - 0 ('<|endoftext|>')
load:   - 2 ('<|im_end|>')
load:   - 4 ('<reponame>')
load: special tokens cache size = 17
load: token to piece cache size = 0.3170 MB
print_info: arch             = llama
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 134.52 M
print_info: general.name     = Smollm2 135M 8k Lc100K Mix1 Ep2
print_info: vocab type       = BPE
print_info: n_vocab          = 49152
print_info: n_merges         = 48900
print_info: BOS token        = 1 '<|im_start|>'
print_info: EOS token        = 2 '<|im_end|>'
print_info: EOT token        = 0 '<|endoftext|>'
print_info: UNK token        = 0 '<|endoftext|>'
print_info: PAD token        = 2 '<|im_end|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM REP token    = 4 '<reponame>'
print_info: EOG token        = 0 '<|endoftext|>'
print_info: EOG token        = 2 '<|im_end|>'
print_info: EOG token        = 4 '<reponame>'
print_info: max token length = 162
llama_model_load: vocab only - skipping tensors
time=2025-11-09T23:24:09.119-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --model /home/dan/.ollama-11459/blobs/sha256-f535f83ec568d040f88ddc04a199fa6da90923bbb41d4dcaed02caa924d6ef57 --port 42777"
time=2025-11-09T23:24:09.119-07:00 level=INFO source=server.go:470 msg="system memory" total="123.6 GiB" free="109.6 GiB" free_swap="0 B"
time=2025-11-09T23:24:09.120-07:00 level=INFO source=memory.go:37 msg="new model will fit in available VRAM across minimum required GPUs, loading" model=/home/dan/.ollama-11459/blobs/sha256-f535f83ec568d040f88ddc04a199fa6da90923bbb41d4dcaed02caa924d6ef57 library=CUDA parallel=1 required="910.5 MiB" gpus=1
time=2025-11-09T23:24:09.120-07:00 level=INFO source=server.go:522 msg=offload library=CUDA layers.requested=-1 layers.model=31 layers.offload=31 layers.split=[31] memory.available="[23.5 GiB]" memory.gpu_overhead="0 B" memory.required.full="910.5 MiB" memory.required.partial="910.5 MiB" memory.required.kv="90.0 MiB" memory.required.allocations="[910.5 MiB]" memory.weights.total="256.6 MiB" memory.weights.repeating="202.6 MiB" memory.weights.nonrepeating="54.0 MiB" memory.graph.full="97.1 MiB" memory.graph.partial="120.4 MiB"
time=2025-11-09T23:24:09.137-07:00 level=INFO source=runner.go:910 msg="starting go runner"
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-229ab403-fd4a-7526-7742-befdb34573e4
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-09T23:24:09.552-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-09T23:24:09.552-07:00 level=INFO source=runner.go:946 msg="Server listening on 127.0.0.1:42777"
time=2025-11-09T23:24:09.556-07:00 level=INFO source=runner.go:845 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:false KvSize:4096 KvCacheType: NumThreads:8 GPULayers:31[ID:GPU-229ab403-fd4a-7526-7742-befdb34573e4 Layers:31(0..30)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:true}"
time=2025-11-09T23:24:09.556-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-09T23:24:09.556-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
ggml_backend_cuda_device_get_memory device GPU-229ab403-fd4a-7526-7742-befdb34573e4 utilizing NVML memory reporting free: 25229787136 total: 25757220864
llama_model_load_from_file_impl: using device CUDA0 (NVIDIA GeForce RTX 4090) (0000:05:00.0) - 24061 MiB free
llama_model_loader: loaded meta data with 33 key-value pairs and 272 tensors from /home/dan/.ollama-11459/blobs/sha256-f535f83ec568d040f88ddc04a199fa6da90923bbb41d4dcaed02caa924d6ef57 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Smollm2 135M 8k Lc100K Mix1 Ep2
llama_model_loader: - kv   3:                       general.organization str              = HuggingFaceTB
llama_model_loader: - kv   4:                           general.finetune str              = 8k-lc100k-mix1-ep2
llama_model_loader: - kv   5:                           general.basename str              = smollm2
llama_model_loader: - kv   6:                         general.size_label str              = 135M
llama_model_loader: - kv   7:                            general.license str              = apache-2.0
llama_model_loader: - kv   8:                          general.languages arr[str,1]       = ["en"]
llama_model_loader: - kv   9:                          llama.block_count u32              = 30
llama_model_loader: - kv  10:                       llama.context_length u32              = 8192
llama_model_loader: - kv  11:                     llama.embedding_length u32              = 576
llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 1536
llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 9
llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 3
llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 100000.000000
llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  17:                          general.file_type u32              = 1
llama_model_loader: - kv  18:                           llama.vocab_size u32              = 49152
llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 64
llama_model_loader: - kv  20:            tokenizer.ggml.add_space_prefix bool             = false
llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = smollm
llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,49152]   = ["<|endoftext|>", "<|im_start|>", "<|...
llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,49152]   = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...
llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,48900]   = ["Ġ t", "Ġ a", "i n", "h e", "Ġ Ġ...
llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 1
llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 2
llama_model_loader: - kv  29:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  30:            tokenizer.ggml.padding_token_id u32              = 2
llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {% for message in messages %}{% if lo...
llama_model_loader: - kv  32:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type  f16:  211 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = F16
print_info: file size   = 256.63 MiB (16.00 BPW) 
load: printing all EOG tokens:
load:   - 0 ('<|endoftext|>')
load:   - 2 ('<|im_end|>')
load:   - 4 ('<reponame>')
load: special tokens cache size = 17
load: token to piece cache size = 0.3170 MB
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: n_ctx_train      = 8192
print_info: n_embd           = 576
print_info: n_layer          = 30
print_info: n_head           = 9
print_info: n_head_kv        = 3
print_info: n_rot            = 64
print_info: n_swa            = 0
print_info: is_swa_any       = 0
print_info: n_embd_head_k    = 64
print_info: n_embd_head_v    = 64
print_info: n_gqa            = 3
print_info: n_embd_k_gqa     = 192
print_info: n_embd_v_gqa     = 192
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-05
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 1536
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: freq_base_train  = 100000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 8192
print_info: rope_finetuned   = unknown
print_info: model type       = 256M
print_info: model params     = 134.52 M
print_info: general.name     = Smollm2 135M 8k Lc100K Mix1 Ep2
print_info: vocab type       = BPE
print_info: n_vocab          = 49152
print_info: n_merges         = 48900
print_info: BOS token        = 1 '<|im_start|>'
print_info: EOS token        = 2 '<|im_end|>'
print_info: EOT token        = 0 '<|endoftext|>'
print_info: UNK token        = 0 '<|endoftext|>'
print_info: PAD token        = 2 '<|im_end|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM REP token    = 4 '<reponame>'
print_info: EOG token        = 0 '<|endoftext|>'
print_info: EOG token        = 2 '<|im_end|>'
print_info: EOG token        = 4 '<reponame>'
print_info: max token length = 162
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: offloading 30 repeating layers to GPU
load_tensors: offloading output layer to GPU
load_tensors: offloaded 31/31 layers to GPU
load_tensors:        CUDA0 model buffer size =   256.63 MiB
load_tensors:   CPU_Mapped model buffer size =    54.00 MiB
llama_init_from_model: model default pooling_type is [0], but [-1] was specified
llama_context: constructing llama_context
llama_context: n_seq_max     = 1
llama_context: n_ctx         = 4096
llama_context: n_ctx_per_seq = 4096
llama_context: n_batch       = 512
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = disabled
llama_context: kv_unified    = false
llama_context: freq_base     = 100000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (4096) < n_ctx_train (8192) -- the full capacity of the model will not be utilized
llama_context:  CUDA_Host  output buffer size =     0.19 MiB
llama_kv_cache:      CUDA0 KV buffer size =    90.00 MiB
llama_kv_cache: size =   90.00 MiB (  4096 cells,  30 layers,  1/1 seqs), K (f16):   45.00 MiB, V (f16):   45.00 MiB
llama_context:      CUDA0 compute buffer size =    97.12 MiB
llama_context:  CUDA_Host compute buffer size =     9.88 MiB
llama_context: graph nodes  = 1086
llama_context: graph splits = 2
time=2025-11-09T23:24:11.563-07:00 level=INFO source=server.go:1289 msg="llama runner started in 2.44 seconds"
time=2025-11-09T23:24:11.564-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-09T23:24:11.564-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-09T23:24:11.564-07:00 level=INFO source=server.go:1289 msg="llama runner started in 2.44 seconds"
[GIN] 2025/11/09 - 23:24:11 | 200 |  3.149117084s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:11 | 200 |   44.408979ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:26 | 200 |   282.59875ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |  436.564402ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |  229.151322ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |  265.258099ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |  144.490757ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |  148.465204ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |    47.39823ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |   57.254571ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:27 | 200 |   68.244368ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:33 | 200 |   744.69024ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:34 | 200 |  848.114881ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:41 | 200 |   1.32831392s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:43 | 200 |  1.147245729s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:45 | 200 |  1.150362234s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:45 | 200 |  922.796793ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:47 | 200 |  2.066262071s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:47 | 200 |  2.057495844s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:49 | 200 |  1.546036732s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:54 | 200 |  225.312272ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:24:54 | 200 |   179.56774ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:00 | 200 |  2.513188741s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:00 | 200 |  1.581775047s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:02 | 200 |  1.280765508s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:02 | 200 |  1.232645358s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:05 | 200 |   191.99391ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:05 | 200 |  183.193419ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:10 | 200 |  1.728611749s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:10 | 200 |   181.04413ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:11 | 200 |  151.129566ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:24 | 200 |  909.314083ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:25 | 200 |  729.153114ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:26 | 200 |  851.885569ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:27 | 200 |  278.111591ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:30 | 200 |  2.596096266s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:30 | 200 |  175.516151ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:46 | 200 |   1.94768985s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:47 | 200 |  2.835107399s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:53 | 200 |  7.160354646s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:54 | 200 |  6.776127859s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:55 | 200 |  3.478629302s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:59 | 200 |  5.834807597s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:59 | 200 |  4.611681164s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:25:59 | 200 |  3.584479544s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:00 | 200 |  657.958431ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:01 | 200 |  2.002740768s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:03 | 200 |  3.418610487s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:03 | 200 |  2.897421973s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:05 | 200 |  3.024424687s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:05 | 200 |  1.620900704s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:11 | 200 |  7.659640916s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:11 | 200 |  6.672318689s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:13 | 200 |  7.876190092s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:13 | 200 |  1.825477165s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:14 | 200 |  2.442327823s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:15 | 200 |  2.486144359s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:16 | 200 |  3.087474005s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:16 | 200 |   1.98073199s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:16 | 200 |  1.231441428s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:18 | 200 |  2.644566796s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:20 | 200 |  3.945380662s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:21 | 200 |  2.669949546s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:25 | 200 |  4.722835415s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:25 | 200 |  3.251185473s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:26 | 200 |  376.067448ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:30 | 200 |  1.632432906s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:30 | 200 |   400.68187ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:31 | 200 |  809.668225ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:35 | 200 |  778.667524ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:35 | 200 |  122.882191ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:36 | 200 |  116.645038ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:40 | 200 |  1.727762778s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:41 | 200 |   1.24875219s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:41 | 200 |  663.988947ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:42 | 200 |   1.62295424s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:43 | 200 |  1.660831536s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:43 | 200 |  870.806516ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:47 | 200 |  4.396971716s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:48 | 200 |  5.386319386s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:48 | 200 |     5.323932s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:49 | 200 |  928.224165ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:52 | 200 |  3.230065551s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:55 | 200 |  2.739365213s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:56 | 200 |  1.373070427s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:56 | 200 |   431.64906ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:57 | 200 |  671.865497ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:57 | 200 |  640.890063ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:26:58 | 200 |  672.204816ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:01 | 200 |  416.630303ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:02 | 200 |   604.74826ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:02 | 200 |  681.471103ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:03 | 200 |  843.526063ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:03 | 200 |  960.391826ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:04 | 200 |  1.475059803s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:05 | 200 |  1.416157534s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:07 | 200 |  2.904715041s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:09 | 200 |  628.533416ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:10 | 200 |   1.14563071s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:11 | 200 |  1.124363396s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:26 | 200 |   903.25965ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:26 | 200 |  111.674616ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:26 | 200 |  126.934784ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:36 | 200 |  711.903414ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:37 | 200 |  941.968769ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:40 | 200 |  1.249733433s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:41 | 200 |  1.382822753s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:42 | 200 |  2.043671641s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:43 | 200 |  1.509259944s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:27:43 | 200 |  307.288896ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:30 | 200 |  1.547191817s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:31 | 200 |  152.311029ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:31 | 200 |  146.062252ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:33 | 200 |  144.175711ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:34 | 200 |  180.704928ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:39 | 200 |  954.851438ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:40 | 200 |  265.128554ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:40 | 200 |   186.64008ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:47 | 200 |  1.511993125s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:48 | 200 |  2.247575834s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:28:51 | 200 |  4.333633285s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:00 | 200 | 11.866311665s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:00 | 200 |  5.294101247s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:05 | 200 |  6.229172294s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:05 | 200 |  4.457995268s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:05 | 200 |  4.386843992s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:05 | 200 |  204.133312ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:06 | 200 |  1.043910542s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:06 | 200 |  403.722766ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:07 | 200 |  925.733417ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:07 | 200 |  924.348589ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:11 | 200 |  169.566237ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:11 | 200 |  162.337991ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:22 | 200 |  1.948110099s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:23 | 200 |  920.964961ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:26 | 200 |  2.904608128s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:27 | 200 |  3.589378791s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:27 | 200 |  1.229985739s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:30 | 200 |  2.824285779s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:32 | 200 |  3.279049051s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:33 | 200 |  661.065139ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:36 | 200 |  192.077878ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:36 | 200 |  227.380387ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:36 | 200 |  588.203951ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:37 | 200 |  842.794119ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:39 | 200 |  2.549333867s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:39 | 200 |  1.128561797s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:41 | 200 |  1.577998264s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/09 - 23:29:41 | 200 |  1.519149862s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-09T23:36:22.378-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:36:22.378-07:00 level=INFO source=images.go:522 msg="total blobs: 6"
time=2025-11-09T23:36:22.378-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:36:22.379-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-09T23:36:22.379-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:36:22.379-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43649"
time=2025-11-09T23:36:22.571-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43881"
time=2025-11-09T23:36:23.054-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 46433"
time=2025-11-09T23:36:23.054-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43409"
time=2025-11-09T23:36:23.267-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:36:27 | 200 |      56.155µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:36:27 | 404 |     329.969µs |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:36:27 | 200 |      16.791µs |       127.0.0.1 | HEAD     "/"
time=2025-11-09T23:36:27.908-07:00 level=INFO source=download.go:177 msg="downloading 735af2139dc6 in 3 100 MB part(s)"
time=2025-11-09T23:36:31.120-07:00 level=INFO source=download.go:177 msg="downloading 4b19ac7dd2fb in 1 476 B part(s)"
time=2025-11-09T23:36:32.345-07:00 level=INFO source=download.go:177 msg="downloading 3e2c24001f9e in 1 8.4 KB part(s)"
time=2025-11-09T23:36:33.563-07:00 level=INFO source=download.go:177 msg="downloading 339e884a40f6 in 1 61 B part(s)"
time=2025-11-09T23:36:34.782-07:00 level=INFO source=download.go:177 msg="downloading 74156d92caf6 in 1 490 B part(s)"
[GIN] 2025/11/09 - 23:36:36 | 200 |  8.628123852s |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/11/09 - 23:41:50 | 200 |     316.444µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:49:18.658-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:49:18.659-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-09T23:49:18.659-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:49:18.660-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-09T23:49:18.660-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:49:18.660-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43451"
time=2025-11-09T23:49:18.930-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35907"
time=2025-11-09T23:49:19.125-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43319"
time=2025-11-09T23:49:19.125-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33493"
time=2025-11-09T23:49:19.335-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:49:23 | 200 |      70.212µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:49:23 | 200 |   44.548194ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:51:25 | 200 |     540.796µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:57:25.823-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:57:25.823-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-09T23:57:25.823-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:57:25.824-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-09T23:57:25.824-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:57:25.825-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33933"
time=2025-11-09T23:57:26.022-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41595"
time=2025-11-09T23:57:26.486-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44389"
time=2025-11-09T23:57:26.486-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 32851"
time=2025-11-09T23:57:26.699-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:57:30 | 200 |      55.975µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:57:30 | 200 |   44.227774ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:59:32 | 200 |     504.668µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:04:44.996-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:04:44.997-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:04:44.997-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:04:44.997-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-10T00:04:44.997-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:04:44.998-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 32913"
time=2025-11-10T00:04:45.451-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 34919"
time=2025-11-10T00:04:45.644-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45047"
time=2025-11-10T00:04:45.644-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33047"
time=2025-11-10T00:04:45.858-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:04:50 | 200 |   14.555999ms |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:04:50 | 200 |   45.717414ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:06:51 | 200 |     365.247µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:10:59.805-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:10:59.806-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:10:59.806-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:10:59.806-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-10T00:10:59.806-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:10:59.807-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42837"
time=2025-11-10T00:11:00.018-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44527"
time=2025-11-10T00:11:00.475-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45977"
time=2025-11-10T00:11:00.475-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 46233"
time=2025-11-10T00:11:00.700-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:11:04 | 200 |      33.373µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:11:04 | 200 |   47.961216ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:13:06 | 200 |     470.614µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:17:37.798-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:17:37.798-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:17:37.798-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:17:37.799-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-10T00:17:37.800-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:17:37.800-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39307"
time=2025-11-10T00:17:38.189-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42217"
time=2025-11-10T00:17:38.397-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45507"
time=2025-11-10T00:17:38.397-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36767"
time=2025-11-10T00:17:38.645-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:17:42 | 200 |      35.837µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:17:42 | 200 |   58.704862ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:19:45 | 200 |     394.882µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:26:01.092-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:26:01.093-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:26:01.093-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:26:01.093-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-10T00:26:01.093-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:26:01.094-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45595"
time=2025-11-10T00:26:01.316-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42883"
time=2025-11-10T00:26:01.532-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45641"
time=2025-11-10T00:26:01.532-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41967"
time=2025-11-10T00:26:01.776-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:26:06 | 200 |      46.938µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:26:06 | 200 |   51.829229ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:28:08 | 200 |     496.753µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:36:59.205-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:36:59.206-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:36:59.206-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:36:59.206-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-10T00:36:59.206-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:36:59.207-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38411"
time=2025-11-10T00:36:59.434-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35053"
time=2025-11-10T00:36:59.741-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38903"
time=2025-11-10T00:36:59.741-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36829"
time=2025-11-10T00:37:00.114-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:37:04 | 200 |      46.888µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:37:04 | 200 |   67.766414ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:39:06 | 200 |     337.313µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:47:33.546-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:47:33.546-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:47:33.546-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:47:33.547-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-10T00:47:33.547-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:47:33.548-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37841"
time=2025-11-10T00:47:33.986-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43815"
time=2025-11-10T00:47:34.196-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45593"
time=2025-11-10T00:47:34.196-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42465"
time=2025-11-10T00:47:34.424-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:47:38 | 200 |      39.785µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:47:38 | 200 |   45.260681ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:49:40 | 200 |     509.917µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:07:33.029-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:07:33.030-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:07:33.030-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:07:33.030-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-10T01:07:33.030-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:07:33.031-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33195"
time=2025-11-10T01:07:33.450-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 34629"
time=2025-11-10T01:07:33.635-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36317"
time=2025-11-10T01:07:33.635-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43025"
time=2025-11-10T01:07:33.844-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:07:38 | 200 |      33.273µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:07:38 | 200 |   45.604166ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:09:40 | 200 |     577.235µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:14:43.975-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:14:43.976-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:14:43.976-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:14:43.976-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-10T01:14:43.976-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:14:43.977-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36371"
time=2025-11-10T01:14:44.170-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43947"
time=2025-11-10T01:14:44.631-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41989"
time=2025-11-10T01:14:44.631-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 34301"
time=2025-11-10T01:14:44.845-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:14:48 | 200 |      49.624µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:14:49 | 200 |   49.992872ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:16:50 | 200 |     477.056µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:28:05.257-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44365"
time=2025-11-10T01:28:07.159-07:00 level=INFO source=server.go:215 msg="enabling flash attention"
time=2025-11-10T01:28:07.159-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /home/dan/.ollama-11459/blobs/sha256-735af2139dc652bf01112746474883d79a52fa1c19038265d363e3d42556f7a2 --port 36169"
time=2025-11-10T01:28:07.160-07:00 level=INFO source=server.go:653 msg="loading model" "model layers"=19 requested=-1
time=2025-11-10T01:28:07.160-07:00 level=INFO source=server.go:658 msg="system memory" total="123.6 GiB" free="89.8 GiB" free_swap="0 B"
time=2025-11-10T01:28:07.160-07:00 level=INFO source=server.go:665 msg="gpu memory" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 library=CUDA available="16.0 GiB" free="16.4 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-10T01:28:07.192-07:00 level=INFO source=runner.go:1349 msg="starting ollama engine"
time=2025-11-10T01:28:07.193-07:00 level=INFO source=runner.go:1384 msg="Server listening on 127.0.0.1:36169"
time=2025-11-10T01:28:07.198-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:28:07.325-07:00 level=INFO source=ggml.go:136 msg="" architecture=gemma3 file_type=Q8_0 name="" description="" num_tensors=236 num_key_values=37
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-874c91aa-3bb2-54a0-534f-860241e77353
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-10T01:28:08.023-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-10T01:28:08.749-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:28:08.864-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:28:08.864-07:00 level=INFO source=ggml.go:482 msg="offloading 18 repeating layers to GPU"
time=2025-11-10T01:28:08.864-07:00 level=INFO source=ggml.go:489 msg="offloading output layer to GPU"
time=2025-11-10T01:28:08.864-07:00 level=INFO source=ggml.go:494 msg="offloaded 19/19 layers to GPU"
time=2025-11-10T01:28:08.865-07:00 level=INFO source=device.go:212 msg="model weights" device=CUDA0 size="271.9 MiB"
time=2025-11-10T01:28:08.865-07:00 level=INFO source=device.go:217 msg="model weights" device=CPU size="170.0 MiB"
time=2025-11-10T01:28:08.865-07:00 level=INFO source=device.go:223 msg="kv cache" device=CUDA0 size="27.0 MiB"
time=2025-11-10T01:28:08.865-07:00 level=INFO source=device.go:234 msg="compute graph" device=CUDA0 size="155.5 MiB"
time=2025-11-10T01:28:08.865-07:00 level=INFO source=device.go:239 msg="compute graph" device=CPU size="1.2 MiB"
time=2025-11-10T01:28:08.865-07:00 level=INFO source=device.go:244 msg="total memory" size="625.6 MiB"
time=2025-11-10T01:28:08.865-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-10T01:28:08.865-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-10T01:28:08.870-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
time=2025-11-10T01:28:09.628-07:00 level=INFO source=server.go:1289 msg="llama runner started in 2.47 seconds"
[GIN] 2025/11/10 - 01:28:11 | 200 |  8.246091891s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:14 | 200 | 10.514977981s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:16 | 200 | 12.410428993s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:19 | 200 | 15.039869853s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:21 | 200 | 17.518596133s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:24 | 200 | 12.207258716s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:26 | 200 | 11.169637191s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:27 | 200 | 10.819009077s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:29 | 200 |  9.634441835s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:30 | 200 |  8.122731729s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:32 | 200 |  8.314006403s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:34 | 200 |  8.291201261s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:36 | 200 |  8.676323742s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:39 | 200 | 10.064344404s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:41 | 200 | 11.348426119s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:43 | 200 | 11.032798057s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:46 | 200 | 11.790819686s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:48 | 200 | 12.096070542s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:51 | 200 | 12.076943219s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:52 | 200 | 10.720349783s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:54 | 200 |  9.985517594s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:56 | 200 |  9.688594399s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:28:58 | 200 |  9.431047847s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:00 | 200 |  8.993874884s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:02 | 200 |  9.651990402s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:04 | 200 | 10.294127104s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:06 | 200 | 10.414560425s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:08 | 200 | 10.441933868s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:10 | 200 | 10.192995687s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:13 | 200 | 10.991456555s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:15 | 200 | 10.881546018s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:17 | 200 |  10.83635983s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:19 | 200 | 10.377787597s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:21 | 200 | 10.210587359s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:23 | 200 |  9.733827037s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:25 | 200 |  9.561381525s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:27 | 200 |  9.458858636s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:34 | 200 | 15.482969221s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:38 | 200 | 16.697878846s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:39 | 200 | 16.094825544s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:42 | 200 |  16.75757713s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:45 | 200 | 17.592330734s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:47 | 200 | 12.373188329s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:49 | 200 | 10.888395445s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:50 | 200 | 11.010531666s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:52 | 200 | 10.189057927s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:54 | 200 |   8.15798088s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:55 | 200 |  8.357128302s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:29:58 | 200 |  8.976537385s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:00 | 200 |  9.956546634s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:03 | 200 | 10.714303904s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:05 | 200 | 11.505429108s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:07 | 200 | 11.714515111s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:10 | 200 | 11.822144098s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:11 | 200 | 10.645849192s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:14 | 200 | 10.433605035s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:16 | 200 | 10.653496316s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:19 | 200 | 11.373350532s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:20 | 200 | 10.220031478s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:22 | 200 | 10.739933451s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:25 | 200 | 11.012728304s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:27 | 200 | 10.899107818s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:30 | 200 | 11.408521215s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:32 | 200 | 12.203557387s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:35 | 200 | 12.354520531s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:37 | 200 | 11.442335474s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:38 | 200 | 11.011565222s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:41 | 200 |  9.990896001s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:43 | 200 | 10.683058641s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:46 | 200 |  9.057528679s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:48 | 200 |  9.150143018s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:50 | 200 |  9.312061937s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:53 | 200 | 11.729722745s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:56 | 200 |  6.029926329s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:30:59 | 200 |  5.091520558s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:00 | 200 |  6.463830985s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:02 | 200 |  4.680773641s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:05 | 200 |  8.408659564s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:08 | 200 |  9.233982157s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:11 | 200 |  9.395946511s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:15 | 200 | 12.818076862s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:17 | 200 | 12.298663216s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:21 | 200 | 14.944089737s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:23 | 200 |  12.29929548s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:25 | 200 | 13.710968627s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:29 | 200 | 13.897469352s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:31 | 200 | 13.724503963s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:33 | 200 | 12.758579065s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:36 | 200 | 10.203636245s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:38 | 200 | 11.348074165s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:41 | 200 | 12.031586353s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:42 | 200 | 10.643952178s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:44 | 200 | 10.752066469s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:48 | 200 | 11.554103092s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:50 | 200 | 12.100224106s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:52 | 200 | 11.690939125s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:54 | 200 | 12.165946588s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:56 | 200 | 11.924385883s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:31:59 | 200 | 11.503658284s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:02 | 200 | 11.300725394s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:05 | 200 | 12.069678089s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:07 | 200 | 12.371130436s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:08 | 200 | 11.704004207s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:10 | 200 | 10.778034507s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:13 | 200 | 11.103335344s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:16 | 200 | 10.578097648s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:19 | 200 | 11.516335401s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:23 | 200 | 13.819402387s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:25 | 200 | 14.406103297s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:28 | 200 |   9.02360139s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:31 | 200 |  10.95375253s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:34 | 200 | 13.273801198s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:36 | 200 |  8.769857708s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:39 | 200 |  6.769533342s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:41 | 200 |  8.155575781s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:44 | 200 |  9.806585099s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:46 | 200 | 10.953529718s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:48 | 200 | 11.082909753s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:50 | 200 | 10.682101238s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:51 | 200 | 10.499244529s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:54 | 200 |  9.696654022s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:32:57 | 200 | 11.029332283s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:01 | 200 |  12.69472648s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:04 | 200 | 14.052363053s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:07 | 200 | 15.901957612s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:09 | 200 | 14.461072237s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:12 | 200 | 14.495623944s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:14 | 200 | 13.185603151s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:16 | 200 | 12.052376548s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:19 | 200 | 11.599337955s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:21 | 200 | 12.131043616s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:23 | 200 | 11.189442081s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:25 | 200 |  8.384116754s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:29 | 200 |  7.291029264s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:32 | 200 | 10.112738704s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:35 | 200 |  10.96536637s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:37 | 200 |  8.832737731s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:40 | 200 | 11.609475613s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:41 | 200 |  3.263830079s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:43 | 200 |  4.166225101s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:46 | 200 |  2.420419148s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:53 | 200 |  2.796862325s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:55 | 200 |  2.561722286s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:33:58 | 200 |  4.297501394s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:00 | 200 |  6.120820224s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:02 | 200 |  6.996069627s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:08 | 200 |  3.138541291s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:22 | 200 |  2.609555538s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:24 | 200 |  2.109878304s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:32 | 200 |  4.932216716s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:34 | 200 |  6.102939101s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:40 | 200 |  3.102597983s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:45 | 200 |  4.140650933s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:48 | 200 |   2.23492772s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:53 | 200 |  3.749804932s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:56 | 200 |   2.74184793s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:34:58 | 200 |  3.512568199s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:01 | 200 |  5.351227671s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:04 | 200 |    8.0111201s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:06 | 200 |  9.920983342s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:08 | 200 |  9.591155708s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:09 | 200 |  7.994158961s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:12 | 200 | 10.431614211s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:13 | 200 |   8.93667445s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:16 | 200 |  6.586783475s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:17 | 200 |  3.780464639s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:47 | 200 |  4.796439697s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:50 | 200 |  7.849665256s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:52 | 200 | 10.095317686s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:54 | 200 | 10.918099221s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:56 | 200 | 13.355273049s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:35:58 | 200 | 10.820377666s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:01 | 200 | 10.240652938s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:04 | 200 | 12.121467737s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:06 | 200 | 12.785613878s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:11 | 200 | 15.125638486s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:16 | 200 | 17.409223879s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:19 | 200 | 18.338887541s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:22 | 200 | 17.082416475s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:24 | 200 | 17.380837855s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:27 | 200 |  15.36759929s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:29 | 200 | 13.372037825s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:32 | 200 | 12.415553516s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:34 | 200 | 12.269095861s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:37 | 200 | 12.399038649s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:39 | 200 | 11.535905575s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:41 | 200 | 11.603372742s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:44 | 200 | 11.935185185s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:46 | 200 | 11.557649253s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:49 | 200 | 12.531797339s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:54 | 200 | 14.859729498s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:55 | 200 | 14.024667495s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:36:58 | 200 | 13.724779863s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:00 | 200 | 14.024410892s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:03 | 200 |   9.89284211s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:06 | 200 | 11.012356358s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:09 | 200 | 13.624107471s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:12 | 200 | 13.400841072s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:15 | 200 | 14.057936664s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:17 | 200 |  13.28674855s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:19 | 200 | 13.188925319s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:21 | 200 | 12.201113914s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:24 | 200 |  8.728592066s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:28 | 200 | 10.376068725s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:31 | 200 | 13.066068517s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:34 | 200 | 12.848185406s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:37 | 200 |  6.706619996s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:38 | 200 |  6.771972835s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:41 | 200 |  7.346539746s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:43 | 200 |  8.367234816s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:45 | 200 |  8.679434364s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:47 | 200 |   8.63624439s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:49 | 200 |  7.560539005s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:52 | 200 |   7.26488512s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:55 | 200 | 10.242572323s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:37:58 | 200 |  8.573769139s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:01 | 200 |  9.200986536s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:03 | 200 |  5.564820861s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:05 | 200 |  5.188663287s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:06 | 200 |  5.807861038s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:08 | 200 |  5.561364293s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:10 | 200 |  6.631978994s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:11 | 200 |  6.012988442s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:14 | 200 |  8.139828696s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:18 | 200 |  4.871896991s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:20 | 200 |  6.694336422s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:22 | 200 |  7.014077732s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:25 | 200 |  7.926882881s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:27 | 200 |  7.776548817s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:30 | 200 |  9.822639075s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:32 | 200 | 10.034993334s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:34 | 200 |  8.146848645s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:38:36.930-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 01:38:36 | 500 |  2.151198518s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:38:36.931-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 01:38:36 | 500 |  3.724975077s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:38:37 | 200 |   9.73712189s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:39:31.091-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:39:31.093-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:39:31.093-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:39:31.093-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-10T01:39:31.094-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:39:31.094-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 34825"
time=2025-11-10T01:39:31.357-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35953"
time=2025-11-10T01:39:31.545-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41009"
time=2025-11-10T01:39:31.545-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38919"
time=2025-11-10T01:39:31.762-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:39:33 | 200 |      67.567µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:39:33 | 200 |   46.779835ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:40:23 | 200 |     571.394µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:40:52.538-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 46385"
time=2025-11-10T01:40:53.770-07:00 level=INFO source=server.go:215 msg="enabling flash attention"
time=2025-11-10T01:40:53.771-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /home/dan/.ollama-11459/blobs/sha256-735af2139dc652bf01112746474883d79a52fa1c19038265d363e3d42556f7a2 --port 37163"
time=2025-11-10T01:40:53.776-07:00 level=INFO source=server.go:653 msg="loading model" "model layers"=19 requested=-1
time=2025-11-10T01:40:53.776-07:00 level=INFO source=server.go:658 msg="system memory" total="123.6 GiB" free="100.9 GiB" free_swap="0 B"
time=2025-11-10T01:40:53.776-07:00 level=INFO source=server.go:665 msg="gpu memory" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 library=CUDA available="20.5 GiB" free="20.9 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-10T01:40:53.795-07:00 level=INFO source=runner.go:1349 msg="starting ollama engine"
time=2025-11-10T01:40:53.795-07:00 level=INFO source=runner.go:1384 msg="Server listening on 127.0.0.1:37163"
time=2025-11-10T01:40:53.799-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:40:53.845-07:00 level=INFO source=ggml.go:136 msg="" architecture=gemma3 file_type=Q8_0 name="" description="" num_tensors=236 num_key_values=37
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-874c91aa-3bb2-54a0-534f-860241e77353
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-10T01:40:54.691-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-10T01:40:56.092-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:40:56.350-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:40:56.351-07:00 level=INFO source=device.go:212 msg="model weights" device=CUDA0 size="271.9 MiB"
time=2025-11-10T01:40:56.351-07:00 level=INFO source=device.go:217 msg="model weights" device=CPU size="170.0 MiB"
time=2025-11-10T01:40:56.351-07:00 level=INFO source=device.go:223 msg="kv cache" device=CUDA0 size="27.0 MiB"
time=2025-11-10T01:40:56.351-07:00 level=INFO source=device.go:234 msg="compute graph" device=CUDA0 size="155.5 MiB"
time=2025-11-10T01:40:56.351-07:00 level=INFO source=device.go:239 msg="compute graph" device=CPU size="1.2 MiB"
time=2025-11-10T01:40:56.351-07:00 level=INFO source=device.go:244 msg="total memory" size="625.6 MiB"
time=2025-11-10T01:40:56.351-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-10T01:40:56.351-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-10T01:40:56.351-07:00 level=INFO source=ggml.go:482 msg="offloading 18 repeating layers to GPU"
time=2025-11-10T01:40:56.351-07:00 level=INFO source=ggml.go:489 msg="offloading output layer to GPU"
time=2025-11-10T01:40:56.351-07:00 level=INFO source=ggml.go:494 msg="offloaded 19/19 layers to GPU"
time=2025-11-10T01:40:56.366-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
time=2025-11-10T01:40:57.120-07:00 level=INFO source=server.go:1289 msg="llama runner started in 3.34 seconds"
[GIN] 2025/11/10 - 01:40:58 | 200 |   5.65680167s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:40:58 | 200 |  822.907995ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:08 | 200 |   871.69886ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:09 | 200 |  1.281097898s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:11 | 200 |  653.748951ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:12 | 200 |  756.143525ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:12 | 200 |  768.415093ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:13 | 200 |  725.462513ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:13 | 200 |  824.114595ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:33 | 200 |  2.612039565s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:36 | 200 |  2.885827886s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:40 | 200 |  1.120600534s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:42 | 200 |  1.512683855s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:41:56.485-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7842 keep=4 new=4096
[GIN] 2025/11/10 - 01:41:57 | 200 |  1.332926325s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:41:58.521-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7937 keep=4 new=4096
[GIN] 2025/11/10 - 01:42:00 | 200 |   3.02081795s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T01:42:02.124-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7937 keep=4 new=4096
[GIN] 2025/11/10 - 01:42:03 | 200 |  2.900120863s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:14 | 200 |  3.393133687s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:19 | 200 |  5.909229465s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:24 | 200 | 10.680225907s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:28 | 200 |    13.654055s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:33 | 200 | 15.593594053s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:37 | 200 | 17.567470838s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:40 | 200 | 20.751194424s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:43 | 200 | 18.679433111s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:47 | 200 | 18.978844221s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:51 | 200 | 18.067154791s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:55 | 200 | 17.710738692s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:01 | 200 | 20.349754798s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:05 | 200 | 21.309237874s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:07 | 200 | 19.656505147s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:12 | 200 | 17.854302077s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:16 | 200 | 20.912801735s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:20 | 200 | 18.408966664s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:23 | 200 | 17.692151501s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:28 | 200 | 20.267935357s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:32 | 200 | 20.013831296s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:36 | 200 | 18.687707064s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:41 | 200 | 21.092036604s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:44 | 200 | 20.121282945s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:47 | 200 | 17.594310267s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:50 | 200 | 12.984453004s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:55 | 200 | 12.289211093s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:00 | 200 |  15.44222214s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:04 | 200 | 16.820254101s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:07 | 200 | 16.957633477s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:11 | 200 | 15.192009758s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:15 | 200 | 13.465792773s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:21 | 200 | 13.429721158s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:27 | 200 | 19.155094906s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:31 | 200 | 15.869697368s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:35 | 200 | 13.614635075s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:38 | 200 |  9.930222937s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:43 | 200 | 11.741206072s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:48 | 200 | 13.268361651s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:54 | 200 | 15.612776556s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:57 | 200 | 15.487317337s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:01 | 200 | 14.040040398s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:04 | 200 | 10.419036243s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:07 | 200 |   9.90977554s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:13 | 200 | 13.735989669s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:18 | 200 | 13.422956234s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:24 | 200 | 11.869685927s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:28 | 200 | 14.337537697s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:30 | 200 | 11.594883617s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:35 | 200 | 11.298949079s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:44 | 200 | 14.009470245s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:47 | 200 | 17.265172915s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:52 | 200 | 16.009016266s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:56 | 200 | 14.474310643s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:05 | 200 | 20.691281673s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:08 | 200 | 19.578114514s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:09 | 200 | 21.208518453s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:12 | 200 | 18.119974778s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:16 | 200 | 19.014749228s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:21 | 200 | 15.617974323s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:26 | 200 | 18.049588046s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:30 | 200 | 17.737394599s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:34 | 200 | 15.169832058s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:39 | 200 | 13.037031603s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:45 | 200 | 18.953477242s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:49 | 200 | 17.815560454s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:52 | 200 | 18.900753809s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:58 | 200 | 23.071003023s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:00 | 200 |  20.09926994s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:03 | 200 | 17.026659929s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:06 | 200 | 13.747331609s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:29 | 200 |  6.839444367s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:34 | 200 | 10.020588715s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:40 | 200 | 15.858900451s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:42 | 200 | 17.482861657s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:44 | 200 | 19.151157922s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:47 | 200 | 11.674885893s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:50 | 200 |  8.698077004s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:55 | 200 |  7.103223714s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:00 | 200 | 10.232512736s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:05 | 200 | 10.705483883s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:09 | 200 | 13.578807738s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:15 | 200 | 14.253439627s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:20 | 200 | 13.410695356s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:23 | 200 |  9.622330787s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:27 | 200 |  8.403368976s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:32 | 200 |  8.315942644s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:37 | 200 | 13.053938739s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:42 | 200 | 12.138575457s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:47 | 200 | 10.761937771s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:51 | 200 |  9.234675099s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:55 | 200 |  7.355958767s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:59 | 200 |  7.826188782s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:03 | 200 |  8.112738284s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:08 | 200 | 12.915922086s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:14 | 200 | 12.629764334s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:15 | 200 |   7.70087769s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:19 | 200 |   4.22917819s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:25 | 200 |  3.837083747s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:31 | 200 |  3.575846441s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:41 | 200 |  7.312676307s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:44 | 200 |  3.849083303s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:50 | 200 |  4.561164931s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:00 | 200 |  8.223961242s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:03 | 200 |  4.685262112s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:12 | 200 |   7.66639314s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:17 | 200 |  5.378444149s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:24 | 200 | 11.023433714s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:29 | 200 | 10.616380484s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:34 | 200 | 10.050188614s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:40 | 200 | 10.358204765s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:46 | 200 | 15.892323339s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:49 | 200 | 12.034771602s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:52 | 200 |  9.815614423s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:56 | 200 |  7.410874243s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:59 | 200 |  6.758924871s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:03 | 200 |  8.928855762s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:07 | 200 | 11.187002171s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:10 | 200 | 10.309742896s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:14 | 200 |  7.173938409s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:18 | 200 |  5.057804046s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:23 | 200 |  8.786116726s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:27 | 200 |  7.960955997s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:31 | 200 |  4.982884564s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:41 | 200 |  8.865522422s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:46 | 200 |  7.112975304s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:49 | 200 |  4.502928447s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:57 | 200 |  7.371071248s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:01 | 200 |  9.257305828s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:05 | 200 |  7.000062378s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:10 | 200 |  8.427129222s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:15 | 200 | 11.068769384s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:21 | 200 | 15.007617963s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:25 | 200 |  18.52340616s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:29 | 200 | 17.228046366s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:34 | 200 | 14.808148465s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:39 | 200 | 12.617762743s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:43 | 200 |  9.781881941s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:45 | 200 |  4.720687573s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:51 | 200 |  5.582705141s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:55 | 200 |  8.988051245s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:00 | 200 |  7.113372483s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:06 | 200 | 11.106922604s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:10 | 200 |  9.499986845s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:13 | 200 | 12.145857572s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:16 | 200 |  8.085488185s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:22 | 200 |   5.31589202s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:27 | 200 |  5.499076228s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:33 | 200 |  5.026009787s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:37 | 200 |  8.771463051s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:41 | 200 |  5.313504678s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:46 | 200 |   5.46685761s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:49 | 200 |  6.353637555s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:58 | 200 |  8.073721714s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:01 | 200 | 11.223596529s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:05 | 200 |  8.490820511s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:09 | 200 |  4.917216143s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:16 | 200 |  5.381576015s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:23 | 200 |  5.349887891s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:32 | 200 |  6.792979728s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:38 | 200 |  5.317125296s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:41 | 200 |  7.843324432s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:45 | 200 |  6.373320353s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:50 | 200 |  3.565615211s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:59 | 200 |  5.084251115s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:03 | 200 |  4.166171457s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:11 | 200 |   4.48624765s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:16 | 200 |  5.346983124s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:19 | 200 |  5.755656411s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:26 | 200 |  6.066137596s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:32 | 200 | 11.410990406s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:38 | 200 | 10.638144316s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:43 | 200 |  9.214367736s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:47 | 200 |  6.600426388s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:52 | 200 |  4.530323976s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:57 | 200 |  4.227014247s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:01 | 200 |  8.566530507s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:04 | 200 |  5.495716775s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:09 | 200 |  4.546096338s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:15 | 200 |   5.17227358s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:19 | 200 |  8.099695191s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:22 | 200 |  5.434627973s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:28 | 200 |  8.138057476s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:33 | 200 | 10.596372396s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:36 | 200 | 13.110260556s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:41 | 200 | 11.585725566s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:45 | 200 |  9.732645503s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:52 | 200 | 15.101894758s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:57 | 200 | 15.212740993s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:02 | 200 | 16.217902552s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:08 | 200 | 19.367364942s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:13 | 200 | 18.198347821s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:19 | 200 | 17.899956158s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:22 | 200 | 14.036487829s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:28 | 200 | 14.500014459s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:31 | 200 | 15.973318802s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:34 | 200 |  13.77710629s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:37 | 200 | 14.615110732s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:42 | 200 | 14.893856969s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:48 | 200 | 15.099397217s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:55 | 200 | 15.957222131s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:57 | 200 | 11.100400544s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:59 | 200 |  7.350200607s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:04 | 200 |  7.048425607s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:08 | 200 | 10.057725544s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:11 | 200 | 11.524386398s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:17 | 200 |  12.76097366s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:24 | 200 | 14.367847523s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:32 | 200 | 20.445632107s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:37 | 200 | 19.451054965s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:41 | 200 | 17.094720817s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:48 | 200 | 17.255568999s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:54 | 200 | 17.007258789s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:00 | 200 | 22.614198838s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:03 | 200 | 19.934840827s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:10 | 200 | 20.160223842s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:12 | 200 | 16.295367787s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:17 | 200 | 16.640276424s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:20 | 200 | 16.843413801s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:24 | 200 | 20.265498281s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:27 | 200 | 16.509823373s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:29 | 200 |  13.79697297s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:31 | 200 |  9.366364837s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:33 | 200 |  6.177891459s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:35 | 200 |  7.775293944s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:38 | 200 |  3.492825231s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:46 | 200 |  4.759865389s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:54 | 200 |  6.141795404s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:00 | 200 |  5.454140832s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:06 | 200 |  5.813789213s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:12 | 200 |   5.56217303s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:19 | 200 |  6.531634105s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:24 | 200 | 11.672046587s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:33 | 200 | 15.112395078s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:37 | 200 | 12.979045344s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:40 | 200 |  9.571494252s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:45 | 200 | 11.981718228s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:49 | 200 | 10.481921603s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:52 | 200 |  13.21891961s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:54 | 200 | 14.014651553s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:58 | 200 | 15.371983298s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:03 | 200 | 14.046920809s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:08 | 200 | 11.665803241s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:12 | 200 |  9.602761564s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:17 | 200 |   8.58922398s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:19 | 200 | 10.837315941s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:24 | 200 | 11.709265613s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:28 | 200 | 13.625048995s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:32 | 200 | 14.818894601s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:36 | 200 | 14.155905041s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:40 | 200 | 11.679403759s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:44 | 200 | 15.934173513s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:48 | 200 | 13.214567976s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:50 | 200 | 10.140253752s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:25 | 200 |  7.237192681s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:27 | 200 |  8.898790353s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:31 | 200 | 11.243476477s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:34 | 200 | 14.233279076s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:40 | 200 | 19.847439344s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:44 | 200 | 15.593629701s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:50 | 200 | 15.757929629s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:56 | 200 | 19.949655763s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:00 | 200 | 18.053260329s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:05 | 200 |  16.42891969s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:10 | 200 | 16.026159833s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:13 | 200 | 12.701640726s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:18 | 200 | 12.988113685s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:21 | 200 | 15.662264545s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:25 | 200 | 13.035614311s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:31 | 200 | 16.760539189s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:34 | 200 | 16.010967982s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:36 | 200 | 17.557574371s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:39 | 200 |  14.34117863s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:46 | 200 | 20.586730707s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:50 | 200 | 18.778420856s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:56 | 200 | 19.392712382s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:00 | 200 | 15.758954149s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:03 | 200 | 13.307811068s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:09 | 200 | 18.325062647s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:15 | 200 | 18.842230073s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:21 | 200 | 18.652837653s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:26 | 200 | 22.082565991s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:31 | 200 | 22.335402013s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:35 | 200 | 21.439795627s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:39 | 200 |  23.60089579s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:44 | 200 | 22.904112997s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:48 | 200 | 21.983640526s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:53 | 200 | 21.984116164s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:58 | 200 | 19.630702939s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:03 | 200 | 23.634193339s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:09 | 200 | 24.924832609s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:16 | 200 |  27.26947692s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:20 | 200 | 26.112199715s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:25 | 200 | 26.821693831s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:29 | 200 | 25.886690316s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:33 | 200 | 23.722736082s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:38 | 200 | 21.318898108s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:42 | 200 | 20.832347315s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:46 | 200 | 17.581248602s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:49 | 200 | 15.819834319s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:54 | 200 | 20.685680681s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:59 | 200 | 19.356011454s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:03 | 200 | 17.047015013s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:06 | 200 | 12.956531077s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:09 | 200 |  8.493070882s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:12 | 200 |  8.586038834s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:16 | 200 |  9.663540487s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:19 | 200 | 13.222387525s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:23 | 200 |  9.734772185s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:27 | 200 |   7.44681625s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:30 | 200 |  4.134468267s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:39 | 200 |  7.259287154s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:43 | 200 |  4.811468295s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:52 | 200 | 12.493547694s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:58 | 200 | 14.017787931s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:06:59.963-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:06:59 | 500 |  8.948136681s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:59 | 500 | 14.323166058s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:07:56.105-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11459 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11459 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T02:07:56.106-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T02:07:56.106-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T02:07:56.106-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11459 (version 0.12.9)"
time=2025-11-10T02:07:56.106-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T02:07:56.107-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35717"
time=2025-11-10T02:07:56.307-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 34017"
time=2025-11-10T02:07:56.763-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44493"
time=2025-11-10T02:07:56.763-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44087"
time=2025-11-10T02:07:56.984-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 02:07:58 | 200 |      89.969µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 02:07:58 | 200 |   50.750616ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 02:08:48 | 200 |     540.314µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T02:09:18.516-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37201"
time=2025-11-10T02:09:19.355-07:00 level=INFO source=server.go:215 msg="enabling flash attention"
time=2025-11-10T02:09:19.356-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /home/dan/.ollama-11459/blobs/sha256-735af2139dc652bf01112746474883d79a52fa1c19038265d363e3d42556f7a2 --port 42685"
time=2025-11-10T02:09:19.357-07:00 level=INFO source=server.go:653 msg="loading model" "model layers"=19 requested=-1
time=2025-11-10T02:09:19.357-07:00 level=INFO source=server.go:658 msg="system memory" total="123.6 GiB" free="102.3 GiB" free_swap="0 B"
time=2025-11-10T02:09:19.357-07:00 level=INFO source=server.go:665 msg="gpu memory" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 library=CUDA available="21.7 GiB" free="22.1 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-10T02:09:19.370-07:00 level=INFO source=runner.go:1349 msg="starting ollama engine"
time=2025-11-10T02:09:19.371-07:00 level=INFO source=runner.go:1384 msg="Server listening on 127.0.0.1:42685"
time=2025-11-10T02:09:19.380-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:19.415-07:00 level=INFO source=ggml.go:136 msg="" architecture=gemma3 file_type=Q8_0 name="" description="" num_tensors=236 num_key_values=37
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-874c91aa-3bb2-54a0-534f-860241e77353
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-10T02:09:20.198-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-10T02:09:21.764-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:21.908-07:00 level=INFO source=device.go:212 msg="model weights" device=CUDA0 size="271.9 MiB"
time=2025-11-10T02:09:21.908-07:00 level=INFO source=device.go:217 msg="model weights" device=CPU size="170.0 MiB"
time=2025-11-10T02:09:21.908-07:00 level=INFO source=device.go:223 msg="kv cache" device=CUDA0 size="27.0 MiB"
time=2025-11-10T02:09:21.908-07:00 level=INFO source=device.go:234 msg="compute graph" device=CUDA0 size="155.5 MiB"
time=2025-11-10T02:09:21.908-07:00 level=INFO source=device.go:239 msg="compute graph" device=CPU size="1.2 MiB"
time=2025-11-10T02:09:21.908-07:00 level=INFO source=device.go:244 msg="total memory" size="625.6 MiB"
time=2025-11-10T02:09:21.908-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-10T02:09:21.908-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-10T02:09:21.906-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-874c91aa-3bb2-54a0-534f-860241e77353 Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:21.906-07:00 level=INFO source=ggml.go:482 msg="offloading 18 repeating layers to GPU"
time=2025-11-10T02:09:21.906-07:00 level=INFO source=ggml.go:489 msg="offloading output layer to GPU"
time=2025-11-10T02:09:21.906-07:00 level=INFO source=ggml.go:494 msg="offloaded 19/19 layers to GPU"
time=2025-11-10T02:09:21.915-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
time=2025-11-10T02:09:22.669-07:00 level=INFO source=server.go:1289 msg="llama runner started in 3.31 seconds"
[GIN] 2025/11/10 - 02:09:23 | 200 |  5.192787216s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:24 | 200 |  1.048164241s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:34 | 200 |   936.60118ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:35 | 200 |  1.003611643s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:35 | 200 |   936.16232ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:36 | 200 |  723.063959ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:37 | 200 |  1.095850345s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:37 | 200 |  906.339106ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:38 | 200 |  978.505276ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:59 | 200 |  1.556956567s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:00 | 200 |  1.745003516s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:10:17.603-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7842 keep=4 new=4096
[GIN] 2025/11/10 - 02:10:18 | 200 |  2.092642049s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:10:19.424-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7959 keep=4 new=4096
[GIN] 2025/11/10 - 02:10:20 | 200 |  1.741474748s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:10:21.387-07:00 level=WARN source=runner.go:171 msg="truncating input prompt" limit=4096 prompt=7941 keep=4 new=4096
[GIN] 2025/11/10 - 02:10:22 | 200 |   1.85336548s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:29 | 200 |  658.753094ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:31 | 200 |  1.379923649s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:32 | 200 |  1.055730966s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:37 | 200 |  1.712156342s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:39 | 200 |  1.473618724s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:39 | 200 |  2.232216111s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:40 | 200 |   1.01271395s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:41 | 200 |  795.907254ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:22 | 200 |  9.118630488s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:28 | 200 | 14.129963464s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:34 | 200 | 18.963988395s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:37 | 200 | 21.269291437s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:41 | 200 | 24.751830253s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:45 | 200 | 28.051173283s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:50 | 200 | 34.205026968s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:54 | 200 |  34.80767412s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:59 | 200 | 39.718583427s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:03 | 200 | 43.485417637s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:06.227-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:06 | 500 | 45.047044832s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:08 | 200 | 47.664859909s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:08 | 500 | 45.045112573s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:11.767-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
time=2025-11-10T02:13:12.299-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:12 | 500 | 45.072272297s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:12 | 500 | 45.071466694s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:14 | 500 | 45.053242295s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:14.701-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:16 | 500 | 45.056614126s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:16.803-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:20 | 200 | 45.739362608s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:23 | 200 | 46.324892878s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:27 | 200 | 45.677348347s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:31 | 200 | 45.738107322s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:34 | 200 | 43.446416528s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:38 | 200 |  43.98533953s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:42 | 200 | 42.698428788s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:47 | 200 | 43.468344819s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:52.039-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:52 | 500 | 45.075627385s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:53 | 200 | 46.962554705s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:54 | 500 | 45.089038887s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:56.615-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:00 | 200 | 25.101316492s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:05 | 200 | 26.787709518s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:10 | 200 | 28.932929593s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:16 | 200 | 33.136013418s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.501-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 |  8.291600018s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.503-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 | 11.007206043s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.503-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 | 15.570895101s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:21 | 200 | 33.259341486s |       127.0.0.1 | POST     "/api/generate"
