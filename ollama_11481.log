time=2025-11-09T23:16:10.452-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:1 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:16:10.452-07:00 level=INFO source=images.go:522 msg="total blobs: 0"
time=2025-11-09T23:16:10.452-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:16:10.452-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-09T23:16:10.452-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:16:10.453-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38951"
time=2025-11-09T23:16:10.658-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44563"
time=2025-11-09T23:16:11.087-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44597"
time=2025-11-09T23:16:11.087-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36989"
time=2025-11-09T23:16:11.306-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-874c91aa-3bb2-54a0-534f-860241e77353 filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:09:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:16:15 | 200 |      61.355µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:16:15 | 404 |     154.509µs |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:16:15 | 200 |      25.558µs |       127.0.0.1 | HEAD     "/"
time=2025-11-09T23:16:15.997-07:00 level=INFO source=download.go:177 msg="downloading f535f83ec568 in 3 100 MB part(s)"
time=2025-11-09T23:16:20.215-07:00 level=INFO source=download.go:177 msg="downloading fbacade46b4d in 1 68 B part(s)"
time=2025-11-09T23:16:21.448-07:00 level=INFO source=download.go:177 msg="downloading d502d55c1d60 in 1 675 B part(s)"
time=2025-11-09T23:16:22.694-07:00 level=INFO source=download.go:177 msg="downloading 58d1e17ffe51 in 1 11 KB part(s)"
time=2025-11-09T23:16:23.908-07:00 level=INFO source=download.go:177 msg="downloading f02dd72bb242 in 1 59 B part(s)"
time=2025-11-09T23:16:25.133-07:00 level=INFO source=download.go:177 msg="downloading b0f58c4c1a3c in 1 561 B part(s)"
[GIN] 2025/11/09 - 23:16:26 | 200 | 10.891671568s |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/11/09 - 23:24:07 | 200 |     464.361µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:41:25.159-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:41:25.159-07:00 level=INFO source=images.go:522 msg="total blobs: 6"
time=2025-11-09T23:41:25.159-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:41:25.159-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-09T23:41:25.159-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:41:25.160-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45353"
time=2025-11-09T23:41:25.634-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33547"
time=2025-11-09T23:41:25.818-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44429"
time=2025-11-09T23:41:25.818-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 46639"
time=2025-11-09T23:41:26.028-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:41:30 | 200 |      45.566µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:41:30 | 404 |     412.083µs |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:41:30 | 200 |      17.002µs |       127.0.0.1 | HEAD     "/"
time=2025-11-09T23:41:30.679-07:00 level=INFO source=download.go:177 msg="downloading 735af2139dc6 in 3 100 MB part(s)"
time=2025-11-09T23:41:34.913-07:00 level=INFO source=download.go:177 msg="downloading 4b19ac7dd2fb in 1 476 B part(s)"
time=2025-11-09T23:41:36.168-07:00 level=INFO source=download.go:177 msg="downloading 3e2c24001f9e in 1 8.4 KB part(s)"
time=2025-11-09T23:41:37.393-07:00 level=INFO source=download.go:177 msg="downloading 339e884a40f6 in 1 61 B part(s)"
time=2025-11-09T23:41:38.623-07:00 level=INFO source=download.go:177 msg="downloading 74156d92caf6 in 1 490 B part(s)"
[GIN] 2025/11/09 - 23:41:39 | 200 |   9.67896762s |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/11/09 - 23:41:50 | 200 |     594.958µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:51:10.077-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:51:10.078-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-09T23:51:10.078-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:51:10.078-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-09T23:51:10.078-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:51:10.079-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41133"
time=2025-11-09T23:51:10.481-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35139"
time=2025-11-09T23:51:10.687-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43449"
time=2025-11-09T23:51:10.687-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35633"
time=2025-11-09T23:51:10.904-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:51:15 | 200 |      30.497µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:51:15 | 200 |   47.013539ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:51:25 | 200 |     290.115µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-09T23:59:17.261-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-09T23:59:17.262-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-09T23:59:17.262-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-09T23:59:17.262-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-09T23:59:17.262-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-09T23:59:17.263-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36939"
time=2025-11-09T23:59:17.469-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 46283"
time=2025-11-09T23:59:17.659-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44925"
time=2025-11-09T23:59:17.659-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38501"
time=2025-11-09T23:59:18.147-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/09 - 23:59:22 | 200 |      54.733µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/09 - 23:59:22 | 200 |   43.618767ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/09 - 23:59:32 | 200 |     517.802µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:06:36.455-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:06:36.456-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:06:36.456-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:06:36.456-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-10T00:06:36.456-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:06:36.457-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45173"
time=2025-11-10T00:06:36.656-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36801"
time=2025-11-10T00:06:36.846-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 42931"
time=2025-11-10T00:06:36.846-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37993"
time=2025-11-10T00:06:37.356-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:06:41 | 200 |       53.45µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:06:41 | 200 |    47.60631ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:06:52 | 200 |     480.532µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:12:51.304-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:12:51.305-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:12:51.305-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:12:51.305-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-10T00:12:51.305-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:12:51.306-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37863"
time=2025-11-10T00:12:51.522-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44263"
time=2025-11-10T00:12:51.721-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45629"
time=2025-11-10T00:12:51.721-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33821"
time=2025-11-10T00:12:51.958-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:12:56 | 200 |      36.288µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:12:56 | 200 |   49.954388ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:13:07 | 200 |     510.779µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:19:29.497-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:19:29.497-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:19:29.497-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:19:29.498-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-10T00:19:29.498-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:19:29.499-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39695"
time=2025-11-10T00:19:29.720-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38989"
time=2025-11-10T00:19:29.931-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45737"
time=2025-11-10T00:19:29.931-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43841"
time=2025-11-10T00:19:30.447-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:19:34 | 200 |      28.683µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:19:34 | 200 |   59.425614ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:19:45 | 200 |     843.654µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:27:52.770-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:27:52.770-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:27:52.771-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:27:52.771-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-10T00:27:52.771-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:27:52.772-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 40973"
time=2025-11-10T00:27:53.157-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45885"
time=2025-11-10T00:27:53.436-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35909"
time=2025-11-10T00:27:53.436-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33435"
time=2025-11-10T00:27:53.657-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:27:57 | 200 |        42.6µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:27:57 | 200 |   46.619225ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:28:08 | 200 |     527.582µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:38:50.700-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:38:50.701-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:38:50.701-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:38:50.701-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-10T00:38:50.701-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:38:50.702-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33769"
time=2025-11-10T00:38:50.900-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 40431"
time=2025-11-10T00:38:51.106-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39537"
time=2025-11-10T00:38:51.106-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36321"
time=2025-11-10T00:38:51.335-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:38:55 | 200 |      33.723µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:38:55 | 200 |   48.676727ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:39:06 | 200 |     566.935µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T00:49:25.011-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T00:49:25.012-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T00:49:25.012-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T00:49:25.012-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-10T00:49:25.012-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T00:49:25.013-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 34413"
time=2025-11-10T00:49:25.220-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41369"
time=2025-11-10T00:49:25.596-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41355"
time=2025-11-10T00:49:25.596-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39295"
time=2025-11-10T00:49:25.895-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 00:49:30 | 200 |    4.597737ms |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 00:49:30 | 200 |   48.185414ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 00:49:40 | 200 |     588.285µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:09:24.566-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:09:24.567-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:09:24.567-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:09:24.567-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-10T01:09:24.567-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:09:24.568-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37297"
time=2025-11-10T01:09:24.761-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35413"
time=2025-11-10T01:09:24.945-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 43597"
time=2025-11-10T01:09:24.946-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 35361"
time=2025-11-10T01:09:25.440-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:09:29 | 200 |      35.417µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:09:29 | 200 |   44.934364ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:09:40 | 200 |     518.173µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:16:35.425-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:16:35.426-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:16:35.426-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:16:35.426-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-10T01:16:35.426-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:16:35.427-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37811"
time=2025-11-10T01:16:35.626-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38181"
time=2025-11-10T01:16:35.815-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 45235"
time=2025-11-10T01:16:35.815-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38313"
time=2025-11-10T01:16:36.295-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:16:40 | 200 |      67.387µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:16:40 | 200 |   46.454662ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:16:51 | 200 |     570.502µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:40:16.529-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T01:40:16.529-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T01:40:16.529-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T01:40:16.530-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-10T01:40:16.530-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T01:40:16.531-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 39813"
time=2025-11-10T01:40:16.730-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 36427"
time=2025-11-10T01:40:16.918-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 33137"
time=2025-11-10T01:40:16.918-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41141"
time=2025-11-10T01:40:17.145-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 01:40:18 | 200 |      51.507µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 01:40:18 | 200 |   45.080149ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 01:40:24 | 200 |     285.607µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T01:41:04.816-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 37235"
time=2025-11-10T01:41:05.131-07:00 level=INFO source=server.go:215 msg="enabling flash attention"
time=2025-11-10T01:41:05.131-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /home/dan/.ollama-11481/blobs/sha256-735af2139dc652bf01112746474883d79a52fa1c19038265d363e3d42556f7a2 --port 41107"
time=2025-11-10T01:41:05.132-07:00 level=INFO source=server.go:653 msg="loading model" "model layers"=19 requested=-1
time=2025-11-10T01:41:05.132-07:00 level=INFO source=server.go:658 msg="system memory" total="123.6 GiB" free="93.9 GiB" free_swap="0 B"
time=2025-11-10T01:41:05.132-07:00 level=INFO source=server.go:665 msg="gpu memory" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f library=CUDA available="17.8 GiB" free="18.2 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-10T01:41:05.146-07:00 level=INFO source=runner.go:1349 msg="starting ollama engine"
time=2025-11-10T01:41:05.146-07:00 level=INFO source=runner.go:1384 msg="Server listening on 127.0.0.1:41107"
time=2025-11-10T01:41:05.155-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:41:05.200-07:00 level=INFO source=ggml.go:136 msg="" architecture=gemma3 file_type=Q8_0 name="" description="" num_tensors=236 num_key_values=37
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-10T01:41:05.593-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-10T01:41:06.805-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:41:07.018-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T01:41:07.018-07:00 level=INFO source=device.go:212 msg="model weights" device=CUDA0 size="271.9 MiB"
time=2025-11-10T01:41:07.018-07:00 level=INFO source=device.go:217 msg="model weights" device=CPU size="170.0 MiB"
time=2025-11-10T01:41:07.018-07:00 level=INFO source=device.go:223 msg="kv cache" device=CUDA0 size="27.0 MiB"
time=2025-11-10T01:41:07.018-07:00 level=INFO source=device.go:234 msg="compute graph" device=CUDA0 size="155.5 MiB"
time=2025-11-10T01:41:07.018-07:00 level=INFO source=device.go:239 msg="compute graph" device=CPU size="1.2 MiB"
time=2025-11-10T01:41:07.018-07:00 level=INFO source=device.go:244 msg="total memory" size="625.6 MiB"
time=2025-11-10T01:41:07.018-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-10T01:41:07.018-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-10T01:41:07.018-07:00 level=INFO source=ggml.go:482 msg="offloading 18 repeating layers to GPU"
time=2025-11-10T01:41:07.018-07:00 level=INFO source=ggml.go:489 msg="offloading output layer to GPU"
time=2025-11-10T01:41:07.019-07:00 level=INFO source=ggml.go:494 msg="offloaded 19/19 layers to GPU"
time=2025-11-10T01:41:07.019-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
time=2025-11-10T01:41:07.522-07:00 level=INFO source=server.go:1289 msg="llama runner started in 2.39 seconds"
[GIN] 2025/11/10 - 01:41:08 | 200 |   3.79642848s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:09 | 200 |  1.042890146s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:29 | 200 |  1.788950803s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:31 | 200 |  1.716268919s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:41:34 | 200 |  2.715269236s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:07 | 200 |  1.777880649s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:09 | 200 |  1.868791829s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:12 | 200 |  3.087013799s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:15 | 200 |  5.092530847s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:19 | 200 |  7.879696024s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:23 | 200 | 10.648362712s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:28 | 200 | 14.161860043s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:34 | 200 | 18.180222222s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:39 | 200 | 22.831762017s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:43 | 200 |  23.18948004s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:47 | 200 | 23.296689657s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:54 | 200 | 24.791453973s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:42:59 | 200 | 24.073635054s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:04 | 200 |  24.36209658s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:10 | 200 | 26.626056783s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:15 | 200 | 27.679650727s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:21 | 200 | 26.967890936s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:26 | 200 | 26.812092107s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:30 | 200 |  25.10529125s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:33 | 200 | 23.030730687s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:38 | 200 | 22.303606788s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:42 | 200 | 20.567462251s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:45 | 200 | 18.427178868s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:49 | 200 | 18.981766198s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:53 | 200 | 18.992997132s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:43:57 | 200 | 17.903897638s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:01 | 200 | 18.779951105s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:05 | 200 | 19.723733804s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:10 | 200 |  20.51098283s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:15 | 200 | 21.776875286s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:19 | 200 | 22.047853146s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:27 | 200 |  25.97689746s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:30 | 200 | 25.060837653s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:35 | 200 | 25.354334307s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:42 | 200 | 26.830231116s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:46 | 200 | 26.550925791s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:51 | 200 | 23.588145377s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:56 | 200 | 24.976211094s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:44:59 | 200 | 23.487371214s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:04 | 200 | 21.655090286s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:06 | 200 | 19.717569013s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:08 | 200 | 16.866524399s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:13 | 200 | 17.056327308s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:18 | 200 | 17.808468014s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:22 | 200 | 16.856840587s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:26 | 200 | 19.301364186s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:30 | 200 | 21.039864182s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:34 | 200 | 20.444423796s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:37 | 200 |  18.89393876s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:41 | 200 | 19.212554715s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:45 | 200 | 18.779813119s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:50 | 200 | 20.199074551s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:45:57 | 200 | 22.742745563s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:03 | 200 | 26.179845236s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:05 | 200 | 23.398002835s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:10 | 200 | 24.687850152s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:13 | 200 | 21.780660576s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:16 | 200 | 18.047718142s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:22 | 200 | 18.912692589s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:25 | 200 | 19.292498032s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:29 | 200 | 19.218679765s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:34 | 200 | 21.242679394s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:40 | 200 | 24.687815911s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:45 | 200 | 22.051594751s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:49 | 200 | 23.632818052s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:52 | 200 | 22.726479199s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:55 | 200 | 20.279045354s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:46:58 | 200 | 17.236561119s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:00 | 200 | 14.305347642s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:03 | 200 | 13.935511541s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:06 | 200 | 13.540354737s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:07 | 200 | 12.081555455s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:09 | 200 | 10.912759472s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:10 | 200 | 10.216865161s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:11 | 200 |  8.084691873s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:12 | 200 |  5.984532179s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:13 | 200 |  5.473503702s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:14 | 200 |  4.604022812s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:14 | 200 |   1.09758259s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:31 | 200 |  7.676299166s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:34 | 200 |  8.556925926s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:40 | 200 | 15.447475748s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:44 | 200 | 19.127389696s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:47 | 200 | 21.794420138s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:51 | 200 | 19.103583395s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:47:54 | 200 | 15.755973705s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:01 | 200 | 16.726393219s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:06 | 200 | 21.419049203s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:10 | 200 | 23.139729978s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:15 | 200 | 23.520669533s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:20 | 200 | 22.032165525s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:25 | 200 | 21.612871761s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:29 | 200 | 19.624437839s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:33 | 200 | 17.655739235s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:37 | 200 | 16.325325013s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:42 | 200 | 21.645889781s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:45 | 200 | 17.334973598s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:48 | 200 | 15.144028505s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:50 | 200 |  16.82911806s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:56 | 200 |  17.14841574s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:48:59 | 200 | 14.992123221s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:07 | 200 | 19.169432888s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:10 | 200 | 18.885815814s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:13 | 200 | 15.938444213s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:19 | 200 | 19.397245317s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:22 | 200 | 18.231998387s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:28 | 200 | 18.033069197s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:34 | 200 | 23.040762229s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:38 | 200 | 19.683692919s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:44 | 200 | 21.260833551s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:49 | 200 | 24.794157569s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:53 | 200 | 23.313782101s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:49:56 | 200 | 19.957357045s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:01 | 200 |  23.09051198s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:07 | 200 | 22.338421527s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:11 | 200 | 21.259289289s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:16 | 200 |  22.01954286s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:20 | 200 | 23.788609754s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:24 | 200 | 22.057906949s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:29 | 200 | 22.733521616s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:32 | 200 | 21.363459176s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:37 | 200 | 20.416925984s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:42 | 200 | 21.738288192s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:47 | 200 | 22.987896145s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:51 | 200 | 20.921238899s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:53 | 200 | 20.349710663s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:50:57 | 200 | 20.243510856s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:01 | 200 | 18.271153179s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:06 | 200 | 18.707938072s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:10 | 200 | 18.984091105s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:14 | 200 | 20.574223719s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:20 | 200 | 22.177125923s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:25 | 200 |  23.96207151s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:33 | 200 | 26.267080169s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:40 | 200 | 30.005947547s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:44 | 200 | 29.623964837s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:48 | 200 | 28.180273193s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:52 | 200 | 26.759825645s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:51:55 | 200 | 22.006847968s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:01 | 200 | 20.111836211s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:06 | 200 | 21.176118769s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:09 | 200 | 20.234348265s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:13 | 200 | 21.339170279s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:18 | 200 | 22.713210006s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:23 | 200 | 21.363488951s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:30 | 200 | 23.256612105s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:34 | 200 | 24.586907261s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:37 | 200 | 22.648252734s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:39 | 200 |  21.28632513s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:42 | 200 | 18.816163873s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:46 | 200 | 15.566253963s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:49 | 200 | 14.203066297s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:52 | 200 | 14.863866149s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:52:58 | 200 |  15.18974461s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:04 | 200 | 21.590640483s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:07 | 200 | 17.028675747s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:11 | 200 | 14.065918772s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:13 | 200 |  8.353053015s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:18 | 200 | 11.001750566s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:20 | 200 |  8.251510678s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:25 | 200 | 11.729607567s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:29 | 200 | 11.139837552s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:35 | 200 | 14.338673122s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:41 | 200 | 15.880509232s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:46 | 200 | 14.212862526s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:48 | 200 |  9.007731549s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:50 | 200 |  3.430643439s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:53:58 | 200 |  7.292997731s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:02 | 200 |  9.893499901s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:06 | 200 |   6.29844809s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:12 | 200 |   5.85099638s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:18 | 200 |   11.4127197s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:21 | 200 |    8.1753331s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:27 | 200 |   5.59301621s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:34 | 200 | 13.074813443s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:38 | 200 |   8.99879251s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:43 | 200 |  7.168618354s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:49 | 200 |  10.34936708s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:55 | 200 | 11.538171526s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:54:58 | 200 |  8.483974483s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:03 | 200 |  7.242291589s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:11 | 200 | 12.158569963s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:15 | 200 | 13.308008066s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:19 | 200 |   9.48396868s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:24 | 200 |  8.882062526s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:29 | 200 | 12.884743569s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:34 | 200 | 13.865755187s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:37 | 200 | 12.765630111s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:42 | 200 |  11.95838846s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:49 | 200 | 12.140051412s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:53 | 200 | 15.054291296s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:57 | 200 | 13.628927435s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:55:59 | 200 |   9.93236516s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:02 | 200 |  12.61320934s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:07 | 200 | 11.509617513s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:12 | 200 |  9.976467764s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:17 | 200 | 15.288825675s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:22 | 200 | 14.027197177s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:27 | 200 | 13.903356331s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:32 | 200 | 12.511073247s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:37 | 200 | 10.822574529s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:41 | 200 |  8.478351362s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:47 | 200 | 14.646788313s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:50 | 200 | 11.532079698s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:56:54 | 200 |  8.698957523s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:01 | 200 | 10.743626558s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:05 | 200 | 14.046118718s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:07 | 200 | 12.828923169s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:09 | 200 | 11.539546332s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:14 | 200 |  9.810349821s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:17 | 200 |  5.780810591s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:24 | 200 |  6.568283709s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:29 | 200 | 11.454183714s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:32 | 200 |  8.903571256s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:33 | 200 |  3.436689694s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:43 | 200 |   9.37152437s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:48 | 200 | 12.380580315s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:54 | 200 |  11.54822251s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:57:59 | 200 | 11.368415903s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:05 | 200 | 15.796733489s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:08 | 200 | 13.076989515s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:11 | 200 | 10.103359295s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:17 | 200 |  9.792873727s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:22 | 200 |  7.911860075s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:27 | 200 |  6.225286797s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:31 | 200 |  8.427118024s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:35 | 200 |  7.760254417s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:43 | 200 |  8.755205306s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:47 | 200 |  7.402575474s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:51 | 200 |    5.6977923s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:58:57 | 200 |  5.254021137s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:04 | 200 | 11.924082008s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:09 | 200 | 11.255201803s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:13 | 200 | 13.274439946s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:17 | 200 | 11.514066534s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:23 | 200 | 10.897229665s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:27 | 200 | 13.120871427s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:33 | 200 |   15.5341221s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:36 | 200 | 17.790352126s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:39 | 200 | 14.407320271s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:41 | 200 | 10.703406015s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:47 | 200 |  9.478278763s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:52 | 200 | 13.169411203s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 01:59:59 | 200 | 17.495878896s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:04 | 200 | 19.137735392s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:07 | 200 | 16.606943264s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:10 | 200 | 13.368805414s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:15 | 200 |  11.05589473s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:24 | 200 | 16.675599981s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:30 | 200 | 20.282916092s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:35 | 200 | 24.654669154s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:40 | 200 | 24.634070958s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:44 | 200 | 22.929687393s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:51 | 200 | 23.557648502s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:00:56 | 200 | 22.774933903s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:02 | 200 | 22.549472925s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:08 | 200 | 23.311651181s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:14 | 200 |  28.08448871s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:18 | 200 | 26.156458707s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:24 | 200 | 24.844085375s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:28 | 200 | 23.073579689s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:32 | 200 |  21.45116607s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:37 | 200 | 19.647822293s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:41 | 200 | 22.627686108s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:48 | 200 | 22.665956989s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:51 | 200 | 22.617736912s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:55 | 200 | 21.697358909s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:56 | 200 | 18.968624723s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:58 | 200 | 15.968953883s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:01:59 | 200 | 10.837134824s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:01 | 200 |  8.874320434s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:02 | 200 |  6.850790648s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:24 | 200 |  6.474148824s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:28 | 200 |  9.362429883s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:32 | 200 | 12.380762663s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:36 | 200 | 16.051823316s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:40 | 200 | 20.374692276s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:43 | 200 | 18.022948468s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:49 | 200 | 17.009797682s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:02:54 | 200 | 15.554966675s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:01 | 200 | 17.482398968s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:09 | 200 | 24.253587981s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:13 | 200 | 21.880969416s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:16 | 200 | 19.604034376s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:21 | 200 | 18.730716039s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:24 | 200 | 14.921939009s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:27 | 200 |  12.84066245s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:31 | 200 | 14.119335145s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:36 | 200 | 13.831250491s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:40 | 200 | 15.740169482s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:44 | 200 | 16.823582178s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:48 | 200 | 20.336592005s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:52 | 200 |  19.43000102s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:03:58 | 200 | 21.831466164s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:02 | 200 | 21.548625852s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:08 | 200 | 21.524863513s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:13 | 200 | 19.347514093s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:14 | 200 | 15.705883824s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:21 | 200 | 18.520631526s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:25 | 200 | 19.998133752s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:29 | 200 | 18.670920619s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:35 | 200 | 20.605265482s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:40 | 200 | 23.262740161s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:43 | 200 | 20.168407492s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:49 | 200 | 23.098456008s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:56 | 200 | 25.484974738s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:04:59 | 200 | 23.882113975s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:04 | 200 | 23.420808899s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:12 | 200 | 28.756655061s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:15 | 200 | 25.833629113s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:19 | 200 | 22.835518752s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:25 | 200 |  24.63904924s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:30 | 200 | 24.927577037s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:34 | 200 | 21.451962002s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:38 | 200 |  19.58183363s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:41 | 200 | 16.695650917s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:46 | 200 | 16.205957294s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:52 | 200 | 17.727893792s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:05:56 | 200 | 20.149545628s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:02 | 200 | 20.493512973s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:07 | 200 | 24.561403201s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:11 | 200 | 21.707671161s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:18 | 200 | 21.209052675s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:22 | 200 | 25.716361686s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:27 | 200 | 24.188665275s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:31 | 200 | 23.308941391s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:35 | 200 | 23.497729497s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:39 | 200 | 20.774035813s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:43 | 200 | 20.580887767s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:49 | 200 | 20.538048731s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:53 | 200 | 21.818286404s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:06:57 | 200 | 21.862864101s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:06:59.994-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:06:59 | 500 |  5.641866701s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:06:59.999-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:06:59 | 500 |  6.595366682s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:07:00.024-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:07:00 | 500 | 11.789001458s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:07:00 | 200 | 18.096505681s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:08:41.541-07:00 level=INFO source=routes.go:1524 msg="server config" env="map[CUDA_VISIBLE_DEVICES:2 GGML_VK_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11481 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/dan/.ollama-11481 OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_REMOTES:[ollama.com] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-11-10T02:08:41.541-07:00 level=INFO source=images.go:522 msg="total blobs: 11"
time=2025-11-10T02:08:41.542-07:00 level=INFO source=images.go:529 msg="total unused blobs removed: 0"
time=2025-11-10T02:08:41.542-07:00 level=INFO source=routes.go:1577 msg="Listening on [::]:11481 (version 0.12.9)"
time=2025-11-10T02:08:41.542-07:00 level=INFO source=runner.go:76 msg="discovering available GPUs..."
time=2025-11-10T02:08:41.542-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 44001"
time=2025-11-10T02:08:41.760-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41043"
time=2025-11-10T02:08:42.202-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 38177"
time=2025-11-10T02:08:42.202-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 41937"
time=2025-11-10T02:08:42.450-07:00 level=INFO source=types.go:42 msg="inference compute" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f filtered_id="" library=CUDA compute=8.9 name=CUDA0 description="NVIDIA GeForce RTX 4090" libdirs=ollama,cuda_v13 driver=13.0 pci_id=0000:0d:00.0 type=discrete total="24.0 GiB" available="23.5 GiB"
[GIN] 2025/11/10 - 02:08:43 | 200 |      48.401µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/11/10 - 02:08:43 | 200 |   45.604345ms |       127.0.0.1 | POST     "/api/show"
[GIN] 2025/11/10 - 02:08:49 | 200 |     608.142µs |       127.0.0.1 | GET      "/api/tags"
time=2025-11-10T02:09:30.212-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --port 40999"
time=2025-11-10T02:09:30.576-07:00 level=INFO source=server.go:215 msg="enabling flash attention"
time=2025-11-10T02:09:30.576-07:00 level=INFO source=server.go:400 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /home/dan/.ollama-11481/blobs/sha256-735af2139dc652bf01112746474883d79a52fa1c19038265d363e3d42556f7a2 --port 38477"
time=2025-11-10T02:09:30.577-07:00 level=INFO source=server.go:653 msg="loading model" "model layers"=19 requested=-1
time=2025-11-10T02:09:30.577-07:00 level=INFO source=server.go:658 msg="system memory" total="123.6 GiB" free="95.3 GiB" free_swap="0 B"
time=2025-11-10T02:09:30.577-07:00 level=INFO source=server.go:665 msg="gpu memory" id=GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f library=CUDA available="17.8 GiB" free="18.2 GiB" minimum="457.0 MiB" overhead="0 B"
time=2025-11-10T02:09:30.591-07:00 level=INFO source=runner.go:1349 msg="starting ollama engine"
time=2025-11-10T02:09:30.592-07:00 level=INFO source=runner.go:1384 msg="Server listening on 127.0.0.1:38477"
time=2025-11-10T02:09:30.599-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:fit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:30.647-07:00 level=INFO source=ggml.go:136 msg="" architecture=gemma3 file_type=Q8_0 name="" description="" num_tensors=236 num_key_values=37
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes, ID: GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f
load_backend: loaded CUDA backend from /usr/local/lib/ollama/cuda_v13/libggml-cuda.so
time=2025-11-10T02:09:30.890-07:00 level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=750,800,860,870,890,900,1000,1030,1100,1200,1210 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-11-10T02:09:31.618-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:alloc LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:32.084-07:00 level=INFO source=runner.go:1222 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:true KvSize:4096 KvCacheType: NumThreads:8 GPULayers:19[ID:GPU-6cab3899-f78d-7304-2676-e0fbf97a3f8f Layers:19(0..18)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-11-10T02:09:32.084-07:00 level=INFO source=ggml.go:482 msg="offloading 18 repeating layers to GPU"
time=2025-11-10T02:09:32.084-07:00 level=INFO source=ggml.go:489 msg="offloading output layer to GPU"
time=2025-11-10T02:09:32.084-07:00 level=INFO source=ggml.go:494 msg="offloaded 19/19 layers to GPU"
time=2025-11-10T02:09:32.084-07:00 level=INFO source=device.go:212 msg="model weights" device=CUDA0 size="271.9 MiB"
time=2025-11-10T02:09:32.084-07:00 level=INFO source=device.go:217 msg="model weights" device=CPU size="170.0 MiB"
time=2025-11-10T02:09:32.084-07:00 level=INFO source=device.go:223 msg="kv cache" device=CUDA0 size="27.0 MiB"
time=2025-11-10T02:09:32.084-07:00 level=INFO source=device.go:234 msg="compute graph" device=CUDA0 size="155.5 MiB"
time=2025-11-10T02:09:32.084-07:00 level=INFO source=device.go:239 msg="compute graph" device=CPU size="1.2 MiB"
time=2025-11-10T02:09:32.084-07:00 level=INFO source=device.go:244 msg="total memory" size="625.6 MiB"
time=2025-11-10T02:09:32.084-07:00 level=INFO source=sched.go:493 msg="loaded runners" count=1
time=2025-11-10T02:09:32.084-07:00 level=INFO source=server.go:1251 msg="waiting for llama runner to start responding"
time=2025-11-10T02:09:32.086-07:00 level=INFO source=server.go:1285 msg="waiting for server to become available" status="llm server loading model"
time=2025-11-10T02:09:32.589-07:00 level=INFO source=server.go:1289 msg="llama runner started in 2.01 seconds"
[GIN] 2025/11/10 - 02:09:33 | 200 |  3.511304903s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:34 | 200 |  910.024386ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:52 | 200 |  1.193197727s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:54 | 200 |  1.574706956s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:09:55 | 200 |  1.544995442s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:20 | 200 |  1.168063751s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:10:22 | 200 |  1.526072303s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:11 | 200 |  799.840486ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:12 | 200 |  1.489038217s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:13 | 200 |  1.640042767s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:15 | 200 |  2.038597108s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:18 | 200 |   3.00911212s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:23 | 200 |  2.135927474s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:25 | 200 |  1.643871528s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:27 | 200 |  1.751890108s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:37 | 200 |  2.303683657s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:38 | 200 |  1.449712394s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:11:40 | 200 |  1.241472995s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:19 | 200 |  6.937747133s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:27 | 200 | 13.599197646s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:32 | 200 | 17.989245695s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:38 | 200 | 22.590453051s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:42 | 200 | 27.058432154s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:46 | 200 | 30.408771487s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:50 | 200 | 30.682603022s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:12:54 | 200 | 34.372186186s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:00 | 200 | 39.143867994s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:04 | 200 | 43.707952269s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:06 | 500 | 45.068614017s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:10 | 200 | 46.203638801s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:11 | 500 |  45.01705883s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:12 | 500 | 45.044501354s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:12 | 500 |   45.1070749s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:13.848-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:15 | 500 | 45.047756224s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:15 | 500 | 45.057233128s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:15.949-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
time=2025-11-10T02:13:17.300-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
time=2025-11-10T02:13:17.323-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:17 | 500 | 45.052698428s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:13:19.112-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
time=2025-11-10T02:13:19.727-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:13:23 | 200 | 45.173870111s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:28 | 200 | 45.377194896s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:32 | 200 | 45.735421557s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:36 | 200 | 45.485371796s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:40 | 200 | 45.125382812s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:44 | 200 |  43.89148131s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:47 | 200 | 42.655078753s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:52 | 200 | 45.880249752s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:13:57 | 200 | 12.889664707s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:02 | 200 |  14.64342088s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:08 | 200 |  8.262143038s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:14 | 200 |  6.247622313s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:21 | 200 | 12.050500852s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:21.453-07:00 level=INFO source=server.go:1433 msg="aborting completion request due to client closing the connection"
[GIN] 2025/11/10 - 02:14:21 | 500 |   3.95969546s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/11/10 - 02:14:21 | 500 |   6.10279019s |       127.0.0.1 | POST     "/api/generate"
time=2025-11-10T02:14:22.631-07:00 level=INFO source=runner.go:868 msg="aborting completion request due to client closing the connection"
